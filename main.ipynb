{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics opencv-python -q\n",
    "!conda install conda-forge::ultralytics\n",
    "!pip install supervision==0.21.0.rc5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample test footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO, solutions\n",
    "# Load the YOLO model\n",
    "model = YOLO(\"yolov9e.pt\")\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"resources/741755_Kazakhstan Traffic Cars Road_By_Danil_Nevsky_Artlist_HD.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\" \n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "classes_to_count = list(range(0, 23))  # classes to count \n",
    "\n",
    "# Define the lines or regions points\n",
    "line_points_1 = [(50, 300), (1000, 250)]  # first line points\n",
    "line_points_2 = [(1400, 750), (1920, 650)]  # second line points\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"sample_object_counting_output.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init Object Counters\n",
    "counter_1 = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=line_points_1,\n",
    "    classes_names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=2,\n",
    "    text_offset=(0, 0),\n",
    "    count_reg_color=(229, 255, 204),\n",
    "    count_bg_color=(229, 255, 204)\n",
    ")\n",
    "\n",
    "counter_2 = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=line_points_2,\n",
    "    classes_names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=2,\n",
    "    text_offset=(-250, 0),\n",
    "    count_reg_color=(153, 153, 255),\n",
    "    count_bg_color=(153, 153, 255)\n",
    ")\n",
    "\n",
    "# Init separate trackers for each counter\n",
    "tracker = model  # Tracker for the first counter\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Perform tracking for the first counter, options: tracker=\"bytetrack.yaml\"\n",
    "    tracks = tracker.track(im0, persist=True, show=False, classes=classes_to_count)\n",
    "            \n",
    "    im0 = counter_1.start_counting(im0, tracks)\n",
    "\n",
    "    # # Perform tracking for the second counter\n",
    "    # im0 = counter_2.start_counting(im0, tracks)\n",
    "    \n",
    "    # Write the frame to the output video\n",
    "    video_writer.write(im0)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real World Footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line Counter Initiated.\n",
      "Line Counter Initiated.\n",
      "Line Counter Initiated.\n",
      "Line Counter Initiated.\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 694.0ms\n",
      "Speed: 1.8ms preprocess, 694.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 2 trucks, 642.7ms\n",
      "Speed: 1.5ms preprocess, 642.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 642.1ms\n",
      "Speed: 1.5ms preprocess, 642.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 672.0ms\n",
      "Speed: 1.5ms preprocess, 672.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 666.1ms\n",
      "Speed: 2.1ms preprocess, 666.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 654.4ms\n",
      "Speed: 1.5ms preprocess, 654.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 694.5ms\n",
      "Speed: 1.6ms preprocess, 694.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 644.9ms\n",
      "Speed: 1.6ms preprocess, 644.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 635.9ms\n",
      "Speed: 1.4ms preprocess, 635.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 650.9ms\n",
      "Speed: 1.3ms preprocess, 650.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 7 cars, 1 truck, 652.2ms\n",
      "Speed: 1.4ms preprocess, 652.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 650.8ms\n",
      "Speed: 1.4ms preprocess, 650.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 669.8ms\n",
      "Speed: 1.8ms preprocess, 669.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 656.2ms\n",
      "Speed: 1.2ms preprocess, 656.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 647.6ms\n",
      "Speed: 1.9ms preprocess, 647.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 678.0ms\n",
      "Speed: 1.1ms preprocess, 678.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 668.5ms\n",
      "Speed: 1.8ms preprocess, 668.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 681.3ms\n",
      "Speed: 1.2ms preprocess, 681.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 657.7ms\n",
      "Speed: 1.5ms preprocess, 657.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 667.1ms\n",
      "Speed: 1.4ms preprocess, 667.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 665.1ms\n",
      "Speed: 1.7ms preprocess, 665.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 655.9ms\n",
      "Speed: 1.5ms preprocess, 655.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 658.2ms\n",
      "Speed: 1.2ms preprocess, 658.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 2 trucks, 1 traffic light, 659.0ms\n",
      "Speed: 1.3ms preprocess, 659.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 trucks, 1 traffic light, 648.8ms\n",
      "Speed: 1.2ms preprocess, 648.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 trucks, 1 traffic light, 673.1ms\n",
      "Speed: 1.4ms preprocess, 673.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 trucks, 1 traffic light, 667.0ms\n",
      "Speed: 1.4ms preprocess, 667.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 trucks, 1 traffic light, 655.3ms\n",
      "Speed: 1.2ms preprocess, 655.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 655.3ms\n",
      "Speed: 1.7ms preprocess, 655.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 646.2ms\n",
      "Speed: 1.2ms preprocess, 646.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 667.8ms\n",
      "Speed: 1.2ms preprocess, 667.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 bus, 1 traffic light, 663.5ms\n",
      "Speed: 1.3ms preprocess, 663.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 bus, 1 truck, 659.2ms\n",
      "Speed: 1.7ms preprocess, 659.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 trucks, 666.1ms\n",
      "Speed: 1.4ms preprocess, 666.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 bus, 1 truck, 654.5ms\n",
      "Speed: 1.2ms preprocess, 654.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 bus, 1 truck, 656.5ms\n",
      "Speed: 1.2ms preprocess, 656.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 bus, 1 truck, 657.8ms\n",
      "Speed: 1.1ms preprocess, 657.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 bus, 1 truck, 664.2ms\n",
      "Speed: 1.8ms preprocess, 664.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 bus, 1 truck, 650.4ms\n",
      "Speed: 1.2ms preprocess, 650.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 bus, 652.8ms\n",
      "Speed: 1.2ms preprocess, 652.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 667.4ms\n",
      "Speed: 1.2ms preprocess, 667.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 668.1ms\n",
      "Speed: 1.7ms preprocess, 668.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 649.9ms\n",
      "Speed: 1.2ms preprocess, 649.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 650.8ms\n",
      "Speed: 1.3ms preprocess, 650.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 661.6ms\n",
      "Speed: 1.2ms preprocess, 661.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 659.0ms\n",
      "Speed: 1.9ms preprocess, 659.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 658.9ms\n",
      "Speed: 1.3ms preprocess, 658.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 652.3ms\n",
      "Speed: 1.3ms preprocess, 652.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 651.0ms\n",
      "Speed: 1.8ms preprocess, 651.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 657.4ms\n",
      "Speed: 1.7ms preprocess, 657.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 659.2ms\n",
      "Speed: 1.4ms preprocess, 659.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 661.4ms\n",
      "Speed: 1.2ms preprocess, 661.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 655.6ms\n",
      "Speed: 1.7ms preprocess, 655.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 652.3ms\n",
      "Speed: 1.2ms preprocess, 652.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 660.0ms\n",
      "Speed: 1.8ms preprocess, 660.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 652.3ms\n",
      "Speed: 1.7ms preprocess, 652.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 656.6ms\n",
      "Speed: 1.7ms preprocess, 656.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 657.1ms\n",
      "Speed: 1.2ms preprocess, 657.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 685.3ms\n",
      "Speed: 1.4ms preprocess, 685.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 646.4ms\n",
      "Speed: 2.0ms preprocess, 646.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 bus, 1 traffic light, 657.2ms\n",
      "Speed: 1.2ms preprocess, 657.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 bus, 1 traffic light, 661.6ms\n",
      "Speed: 1.3ms preprocess, 661.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 bus, 1 traffic light, 672.9ms\n",
      "Speed: 1.6ms preprocess, 672.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 bus, 1 traffic light, 661.8ms\n",
      "Speed: 1.2ms preprocess, 661.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 bus, 1 traffic light, 660.7ms\n",
      "Speed: 1.8ms preprocess, 660.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 bus, 1 traffic light, 652.2ms\n",
      "Speed: 1.2ms preprocess, 652.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 bus, 1 traffic light, 650.2ms\n",
      "Speed: 1.4ms preprocess, 650.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 bus, 1 traffic light, 652.8ms\n",
      "Speed: 1.9ms preprocess, 652.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 bus, 2 traffic lights, 645.9ms\n",
      "Speed: 1.2ms preprocess, 645.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 bus, 2 traffic lights, 668.3ms\n",
      "Speed: 1.2ms preprocess, 668.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 bus, 1 traffic light, 661.3ms\n",
      "Speed: 1.2ms preprocess, 661.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 9 cars, 1 bus, 1 traffic light, 659.7ms\n",
      "Speed: 1.2ms preprocess, 659.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 bus, 1 traffic light, 673.8ms\n",
      "Speed: 1.4ms preprocess, 673.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 bus, 1 traffic light, 645.4ms\n",
      "Speed: 1.2ms preprocess, 645.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 bus, 1 traffic light, 645.8ms\n",
      "Speed: 1.5ms preprocess, 645.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 bus, 1 traffic light, 667.4ms\n",
      "Speed: 1.3ms preprocess, 667.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 bus, 1 traffic light, 696.8ms\n",
      "Speed: 1.2ms preprocess, 696.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 bus, 1 traffic light, 720.3ms\n",
      "Speed: 1.2ms preprocess, 720.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 bus, 1 traffic light, 656.9ms\n",
      "Speed: 1.3ms preprocess, 656.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 truck, 1 traffic light, 686.6ms\n",
      "Speed: 1.2ms preprocess, 686.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 truck, 1 traffic light, 680.4ms\n",
      "Speed: 1.2ms preprocess, 680.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 truck, 1 traffic light, 668.3ms\n",
      "Speed: 1.2ms preprocess, 668.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 2 buss, 1 truck, 1 traffic light, 649.5ms\n",
      "Speed: 1.3ms preprocess, 649.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 bus, 1 truck, 1 traffic light, 648.2ms\n",
      "Speed: 1.2ms preprocess, 648.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 bus, 1 truck, 1 traffic light, 647.8ms\n",
      "Speed: 1.7ms preprocess, 647.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 3 trucks, 1 traffic light, 678.5ms\n",
      "Speed: 1.5ms preprocess, 678.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 3 trucks, 1 traffic light, 642.9ms\n",
      "Speed: 1.2ms preprocess, 642.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 1 traffic light, 638.7ms\n",
      "Speed: 1.7ms preprocess, 638.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 1 traffic light, 643.0ms\n",
      "Speed: 1.2ms preprocess, 643.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 1 traffic light, 629.8ms\n",
      "Speed: 1.4ms preprocess, 629.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 1 traffic light, 630.7ms\n",
      "Speed: 1.5ms preprocess, 630.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 631.9ms\n",
      "Speed: 1.7ms preprocess, 631.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 2 trucks, 634.7ms\n",
      "Speed: 1.3ms preprocess, 634.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 2 trucks, 637.3ms\n",
      "Speed: 1.2ms preprocess, 637.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 2 trucks, 621.6ms\n",
      "Speed: 1.7ms preprocess, 621.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 633.6ms\n",
      "Speed: 1.7ms preprocess, 633.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 640.9ms\n",
      "Speed: 1.7ms preprocess, 640.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 2 trucks, 626.4ms\n",
      "Speed: 1.1ms preprocess, 626.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 3 trucks, 626.7ms\n",
      "Speed: 1.7ms preprocess, 626.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 2 trucks, 626.7ms\n",
      "Speed: 1.2ms preprocess, 626.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 2 trucks, 630.3ms\n",
      "Speed: 1.1ms preprocess, 630.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 2 trucks, 628.5ms\n",
      "Speed: 1.7ms preprocess, 628.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 1 truck, 630.4ms\n",
      "Speed: 1.7ms preprocess, 630.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 1 truck, 623.2ms\n",
      "Speed: 1.7ms preprocess, 623.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 618.9ms\n",
      "Speed: 1.2ms preprocess, 618.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 623.0ms\n",
      "Speed: 1.1ms preprocess, 623.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 2 trucks, 631.4ms\n",
      "Speed: 1.2ms preprocess, 631.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 633.0ms\n",
      "Speed: 1.2ms preprocess, 633.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 641.6ms\n",
      "Speed: 1.2ms preprocess, 641.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 bus, 2 trucks, 632.9ms\n",
      "Speed: 1.5ms preprocess, 632.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 634.9ms\n",
      "Speed: 1.5ms preprocess, 634.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 635.9ms\n",
      "Speed: 1.2ms preprocess, 635.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 6 cars, 1 bus, 1 truck, 635.4ms\n",
      "Speed: 1.7ms preprocess, 635.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 636.4ms\n",
      "Speed: 1.7ms preprocess, 636.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 642.9ms\n",
      "Speed: 1.8ms preprocess, 642.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 6 cars, 1 bus, 629.7ms\n",
      "Speed: 1.7ms preprocess, 629.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 639.8ms\n",
      "Speed: 1.7ms preprocess, 639.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 6 cars, 1 bus, 630.0ms\n",
      "Speed: 1.7ms preprocess, 630.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 6 cars, 1 bus, 635.4ms\n",
      "Speed: 1.7ms preprocess, 635.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 633.7ms\n",
      "Speed: 1.7ms preprocess, 633.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 632.2ms\n",
      "Speed: 1.2ms preprocess, 632.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 637.7ms\n",
      "Speed: 1.5ms preprocess, 637.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 629.3ms\n",
      "Speed: 1.2ms preprocess, 629.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 636.2ms\n",
      "Speed: 1.2ms preprocess, 636.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 1 traffic light, 633.7ms\n",
      "Speed: 1.2ms preprocess, 633.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 625.2ms\n",
      "Speed: 1.2ms preprocess, 625.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 636.8ms\n",
      "Speed: 1.6ms preprocess, 636.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 2 traffic lights, 628.2ms\n",
      "Speed: 1.2ms preprocess, 628.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 623.7ms\n",
      "Speed: 1.4ms preprocess, 623.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 630.1ms\n",
      "Speed: 1.2ms preprocess, 630.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 640.0ms\n",
      "Speed: 1.7ms preprocess, 640.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 629.6ms\n",
      "Speed: 1.2ms preprocess, 629.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 bus, 1 truck, 1 traffic light, 634.9ms\n",
      "Speed: 1.2ms preprocess, 634.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 632.1ms\n",
      "Speed: 1.1ms preprocess, 632.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 bus, 1 truck, 1 traffic light, 640.6ms\n",
      "Speed: 1.8ms preprocess, 640.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 1 traffic light, 633.1ms\n",
      "Speed: 1.7ms preprocess, 633.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 1 traffic light, 631.8ms\n",
      "Speed: 1.2ms preprocess, 631.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 1 traffic light, 630.9ms\n",
      "Speed: 1.2ms preprocess, 630.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 1 traffic light, 629.5ms\n",
      "Speed: 1.7ms preprocess, 629.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 1 traffic light, 634.0ms\n",
      "Speed: 1.2ms preprocess, 634.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 1 traffic light, 633.7ms\n",
      "Speed: 1.9ms preprocess, 633.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 629.4ms\n",
      "Speed: 1.2ms preprocess, 629.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 1 truck, 640.1ms\n",
      "Speed: 1.2ms preprocess, 640.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 639.6ms\n",
      "Speed: 1.2ms preprocess, 639.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 632.9ms\n",
      "Speed: 1.7ms preprocess, 632.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 636.1ms\n",
      "Speed: 1.1ms preprocess, 636.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 638.9ms\n",
      "Speed: 1.9ms preprocess, 638.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 627.5ms\n",
      "Speed: 1.5ms preprocess, 627.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 641.2ms\n",
      "Speed: 1.2ms preprocess, 641.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 635.3ms\n",
      "Speed: 1.4ms preprocess, 635.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 633.1ms\n",
      "Speed: 1.2ms preprocess, 633.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 630.5ms\n",
      "Speed: 1.7ms preprocess, 630.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 bus, 645.8ms\n",
      "Speed: 1.6ms preprocess, 645.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 bus, 649.0ms\n",
      "Speed: 1.2ms preprocess, 649.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 bus, 1 truck, 635.2ms\n",
      "Speed: 1.6ms preprocess, 635.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 1 truck, 628.7ms\n",
      "Speed: 1.2ms preprocess, 628.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 1 truck, 633.8ms\n",
      "Speed: 1.2ms preprocess, 633.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 bus, 1 truck, 633.6ms\n",
      "Speed: 1.2ms preprocess, 633.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 1 traffic light, 642.2ms\n",
      "Speed: 1.4ms preprocess, 642.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 1 traffic light, 616.9ms\n",
      "Speed: 1.2ms preprocess, 616.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 1 traffic light, 620.3ms\n",
      "Speed: 1.6ms preprocess, 620.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 2 trucks, 1 traffic light, 630.6ms\n",
      "Speed: 1.2ms preprocess, 630.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 1 traffic light, 633.4ms\n",
      "Speed: 1.2ms preprocess, 633.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bicycle, 8 cars, 1 truck, 1 traffic light, 626.5ms\n",
      "Speed: 1.8ms preprocess, 626.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 1 traffic light, 629.5ms\n",
      "Speed: 1.2ms preprocess, 629.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 1 traffic light, 628.1ms\n",
      "Speed: 1.2ms preprocess, 628.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 2 trucks, 1 traffic light, 625.7ms\n",
      "Speed: 1.2ms preprocess, 625.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 2 trucks, 1 traffic light, 634.6ms\n",
      "Speed: 1.7ms preprocess, 634.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 634.5ms\n",
      "Speed: 1.8ms preprocess, 634.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 633.5ms\n",
      "Speed: 1.1ms preprocess, 633.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 636.7ms\n",
      "Speed: 1.8ms preprocess, 636.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 630.1ms\n",
      "Speed: 1.2ms preprocess, 630.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 629.8ms\n",
      "Speed: 1.8ms preprocess, 629.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 636.2ms\n",
      "Speed: 1.4ms preprocess, 636.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bicycle, 5 cars, 1 truck, 1 traffic light, 634.9ms\n",
      "Speed: 1.2ms preprocess, 634.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 627.1ms\n",
      "Speed: 1.2ms preprocess, 627.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 629.0ms\n",
      "Speed: 1.2ms preprocess, 629.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 637.5ms\n",
      "Speed: 1.2ms preprocess, 637.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 1 traffic light, 624.3ms\n",
      "Speed: 1.3ms preprocess, 624.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 1 traffic light, 629.2ms\n",
      "Speed: 1.1ms preprocess, 629.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 1 traffic light, 630.1ms\n",
      "Speed: 1.8ms preprocess, 630.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 1 traffic light, 630.7ms\n",
      "Speed: 1.1ms preprocess, 630.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 1 traffic light, 625.5ms\n",
      "Speed: 1.2ms preprocess, 625.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 1 traffic light, 637.6ms\n",
      "Speed: 1.5ms preprocess, 637.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 truck, 1 traffic light, 637.0ms\n",
      "Speed: 1.2ms preprocess, 637.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 633.4ms\n",
      "Speed: 1.4ms preprocess, 633.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 633.2ms\n",
      "Speed: 1.4ms preprocess, 633.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 636.4ms\n",
      "Speed: 1.4ms preprocess, 636.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 629.6ms\n",
      "Speed: 1.1ms preprocess, 629.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 642.2ms\n",
      "Speed: 1.7ms preprocess, 642.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 632.6ms\n",
      "Speed: 1.6ms preprocess, 632.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 627.7ms\n",
      "Speed: 1.7ms preprocess, 627.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 636.6ms\n",
      "Speed: 1.2ms preprocess, 636.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 632.7ms\n",
      "Speed: 1.3ms preprocess, 632.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 631.1ms\n",
      "Speed: 1.2ms preprocess, 631.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 630.9ms\n",
      "Speed: 1.2ms preprocess, 630.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 624.6ms\n",
      "Speed: 1.7ms preprocess, 624.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 637.4ms\n",
      "Speed: 1.2ms preprocess, 637.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 634.8ms\n",
      "Speed: 1.2ms preprocess, 634.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 636.4ms\n",
      "Speed: 1.2ms preprocess, 636.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 633.6ms\n",
      "Speed: 1.2ms preprocess, 633.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 644.0ms\n",
      "Speed: 1.8ms preprocess, 644.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 637.4ms\n",
      "Speed: 1.4ms preprocess, 637.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 traffic light, 641.1ms\n",
      "Speed: 1.7ms preprocess, 641.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 629.8ms\n",
      "Speed: 1.2ms preprocess, 629.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 636.3ms\n",
      "Speed: 1.1ms preprocess, 636.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 640.7ms\n",
      "Speed: 1.2ms preprocess, 640.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 642.9ms\n",
      "Speed: 1.2ms preprocess, 642.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 643.6ms\n",
      "Speed: 1.2ms preprocess, 643.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 640.9ms\n",
      "Speed: 1.2ms preprocess, 640.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 644.9ms\n",
      "Speed: 1.5ms preprocess, 644.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 640.3ms\n",
      "Speed: 1.3ms preprocess, 640.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 632.8ms\n",
      "Speed: 1.8ms preprocess, 632.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 632.8ms\n",
      "Speed: 1.2ms preprocess, 632.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 639.3ms\n",
      "Speed: 1.2ms preprocess, 639.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 2 trucks, 1 traffic light, 647.2ms\n",
      "Speed: 1.2ms preprocess, 647.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 2 trucks, 1 traffic light, 640.9ms\n",
      "Speed: 1.1ms preprocess, 640.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 2 trucks, 1 traffic light, 655.2ms\n",
      "Speed: 1.4ms preprocess, 655.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 2 trucks, 1 traffic light, 648.1ms\n",
      "Speed: 1.2ms preprocess, 648.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 637.5ms\n",
      "Speed: 1.2ms preprocess, 637.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 641.3ms\n",
      "Speed: 1.1ms preprocess, 641.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 646.7ms\n",
      "Speed: 1.2ms preprocess, 646.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 2 trucks, 1 traffic light, 649.6ms\n",
      "Speed: 1.2ms preprocess, 649.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 2 trucks, 1 traffic light, 646.8ms\n",
      "Speed: 1.2ms preprocess, 646.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 643.2ms\n",
      "Speed: 1.6ms preprocess, 643.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 641.9ms\n",
      "Speed: 1.2ms preprocess, 641.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 640.4ms\n",
      "Speed: 1.5ms preprocess, 640.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 645.3ms\n",
      "Speed: 2.3ms preprocess, 645.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 638.0ms\n",
      "Speed: 1.4ms preprocess, 638.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 1 traffic light, 634.8ms\n",
      "Speed: 1.7ms preprocess, 634.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 2 trucks, 1 traffic light, 641.3ms\n",
      "Speed: 2.2ms preprocess, 641.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 637.3ms\n",
      "Speed: 1.5ms preprocess, 637.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 631.4ms\n",
      "Speed: 1.2ms preprocess, 631.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 1 traffic light, 640.5ms\n",
      "Speed: 2.3ms preprocess, 640.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 traffic light, 643.2ms\n",
      "Speed: 1.5ms preprocess, 643.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 traffic light, 643.0ms\n",
      "Speed: 1.8ms preprocess, 643.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 639.0ms\n",
      "Speed: 1.2ms preprocess, 639.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 traffic light, 651.7ms\n",
      "Speed: 1.7ms preprocess, 651.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 traffic light, 659.2ms\n",
      "Speed: 1.2ms preprocess, 659.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 609.2ms\n",
      "Speed: 1.4ms preprocess, 609.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 630.4ms\n",
      "Speed: 1.3ms preprocess, 630.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 642.8ms\n",
      "Speed: 1.2ms preprocess, 642.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 639.2ms\n",
      "Speed: 1.5ms preprocess, 639.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 629.6ms\n",
      "Speed: 1.8ms preprocess, 629.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 642.9ms\n",
      "Speed: 1.8ms preprocess, 642.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 634.0ms\n",
      "Speed: 1.5ms preprocess, 634.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 636.0ms\n",
      "Speed: 1.3ms preprocess, 636.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 641.7ms\n",
      "Speed: 1.2ms preprocess, 641.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 1 traffic light, 643.1ms\n",
      "Speed: 1.7ms preprocess, 643.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 9 cars, 1 traffic light, 633.6ms\n",
      "Speed: 1.2ms preprocess, 633.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 9 cars, 1 traffic light, 634.0ms\n",
      "Speed: 1.2ms preprocess, 634.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 9 cars, 1 traffic light, 637.9ms\n",
      "Speed: 1.2ms preprocess, 637.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 9 cars, 1 traffic light, 637.9ms\n",
      "Speed: 1.2ms preprocess, 637.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 9 cars, 1 traffic light, 639.3ms\n",
      "Speed: 1.3ms preprocess, 639.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 632.6ms\n",
      "Speed: 1.6ms preprocess, 632.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 630.5ms\n",
      "Speed: 1.7ms preprocess, 630.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 636.4ms\n",
      "Speed: 1.7ms preprocess, 636.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 634.2ms\n",
      "Speed: 1.7ms preprocess, 634.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 620.7ms\n",
      "Speed: 2.2ms preprocess, 620.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 634.7ms\n",
      "Speed: 1.6ms preprocess, 634.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 631.1ms\n",
      "Speed: 1.6ms preprocess, 631.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 634.0ms\n",
      "Speed: 1.4ms preprocess, 634.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 642.5ms\n",
      "Speed: 1.2ms preprocess, 642.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 traffic light, 637.4ms\n",
      "Speed: 1.2ms preprocess, 637.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 629.1ms\n",
      "Speed: 1.2ms preprocess, 629.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 traffic light, 631.8ms\n",
      "Speed: 1.1ms preprocess, 631.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 traffic light, 644.0ms\n",
      "Speed: 2.3ms preprocess, 644.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 631.7ms\n",
      "Speed: 1.6ms preprocess, 631.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 623.8ms\n",
      "Speed: 1.7ms preprocess, 623.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 631.9ms\n",
      "Speed: 1.2ms preprocess, 631.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 624.4ms\n",
      "Speed: 1.2ms preprocess, 624.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 625.4ms\n",
      "Speed: 1.2ms preprocess, 625.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 631.3ms\n",
      "Speed: 1.2ms preprocess, 631.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 631.0ms\n",
      "Speed: 1.3ms preprocess, 631.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 traffic light, 635.0ms\n",
      "Speed: 1.7ms preprocess, 635.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 1 traffic light, 637.2ms\n",
      "Speed: 1.7ms preprocess, 637.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 1 traffic light, 630.3ms\n",
      "Speed: 1.7ms preprocess, 630.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 9 cars, 636.6ms\n",
      "Speed: 1.1ms preprocess, 636.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 632.3ms\n",
      "Speed: 1.2ms preprocess, 632.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 630.6ms\n",
      "Speed: 1.7ms preprocess, 630.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 623.0ms\n",
      "Speed: 2.1ms preprocess, 623.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 631.7ms\n",
      "Speed: 1.2ms preprocess, 631.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 642.0ms\n",
      "Speed: 1.6ms preprocess, 642.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 636.6ms\n",
      "Speed: 1.8ms preprocess, 636.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 633.4ms\n",
      "Speed: 2.0ms preprocess, 633.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 631.3ms\n",
      "Speed: 1.2ms preprocess, 631.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 truck, 629.0ms\n",
      "Speed: 1.2ms preprocess, 629.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 truck, 637.0ms\n",
      "Speed: 2.1ms preprocess, 637.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 truck, 642.6ms\n",
      "Speed: 1.2ms preprocess, 642.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 truck, 641.5ms\n",
      "Speed: 1.1ms preprocess, 641.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 motorcycle, 636.7ms\n",
      "Speed: 1.3ms preprocess, 636.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 motorcycle, 640.5ms\n",
      "Speed: 1.1ms preprocess, 640.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 motorcycle, 631.8ms\n",
      "Speed: 1.2ms preprocess, 631.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 motorcycle, 634.1ms\n",
      "Speed: 1.2ms preprocess, 634.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 motorcycle, 632.3ms\n",
      "Speed: 1.2ms preprocess, 632.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 motorcycle, 1 traffic light, 643.2ms\n",
      "Speed: 1.7ms preprocess, 643.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 motorcycle, 1 traffic light, 640.3ms\n",
      "Speed: 1.7ms preprocess, 640.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 motorcycle, 1 traffic light, 632.2ms\n",
      "Speed: 1.2ms preprocess, 632.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 motorcycle, 1 traffic light, 629.9ms\n",
      "Speed: 1.5ms preprocess, 629.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 motorcycle, 1 traffic light, 636.6ms\n",
      "Speed: 1.2ms preprocess, 636.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 motorcycle, 1 traffic light, 633.1ms\n",
      "Speed: 1.2ms preprocess, 633.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 motorcycle, 1 traffic light, 633.2ms\n",
      "Speed: 1.1ms preprocess, 633.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 motorcycle, 1 traffic light, 630.4ms\n",
      "Speed: 1.2ms preprocess, 630.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 motorcycle, 1 traffic light, 622.3ms\n",
      "Speed: 1.2ms preprocess, 622.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 motorcycle, 1 traffic light, 621.5ms\n",
      "Speed: 1.2ms preprocess, 621.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 motorcycle, 1 traffic light, 621.6ms\n",
      "Speed: 1.5ms preprocess, 621.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 motorcycle, 1 traffic light, 629.4ms\n",
      "Speed: 1.8ms preprocess, 629.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 motorcycle, 1 traffic light, 631.1ms\n",
      "Speed: 1.2ms preprocess, 631.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 motorcycle, 1 traffic light, 629.4ms\n",
      "Speed: 1.9ms preprocess, 629.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 bicycle, 8 cars, 1 motorcycle, 1 traffic light, 634.5ms\n",
      "Speed: 1.9ms preprocess, 634.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 motorcycle, 1 traffic light, 638.0ms\n",
      "Speed: 2.0ms preprocess, 638.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 motorcycle, 1 truck, 1 traffic light, 627.1ms\n",
      "Speed: 1.9ms preprocess, 627.1ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 motorcycle, 1 truck, 1 traffic light, 629.1ms\n",
      "Speed: 1.9ms preprocess, 629.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 motorcycle, 1 traffic light, 637.9ms\n",
      "Speed: 1.9ms preprocess, 637.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 motorcycle, 1 traffic light, 644.3ms\n",
      "Speed: 2.0ms preprocess, 644.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 motorcycle, 1 traffic light, 644.4ms\n",
      "Speed: 1.9ms preprocess, 644.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 motorcycle, 1 traffic light, 625.7ms\n",
      "Speed: 1.2ms preprocess, 625.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 motorcycle, 1 traffic light, 631.7ms\n",
      "Speed: 1.8ms preprocess, 631.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 traffic light, 630.8ms\n",
      "Speed: 1.2ms preprocess, 630.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 657.8ms\n",
      "Speed: 1.2ms preprocess, 657.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 traffic light, 606.6ms\n",
      "Speed: 1.1ms preprocess, 606.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 643.7ms\n",
      "Speed: 1.4ms preprocess, 643.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 636.2ms\n",
      "Speed: 1.8ms preprocess, 636.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 627.0ms\n",
      "Speed: 1.2ms preprocess, 627.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 637.1ms\n",
      "Speed: 1.2ms preprocess, 637.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 trucks, 645.0ms\n",
      "Speed: 1.1ms preprocess, 645.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 trucks, 630.5ms\n",
      "Speed: 1.2ms preprocess, 630.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 trucks, 629.5ms\n",
      "Speed: 1.2ms preprocess, 629.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 trucks, 626.8ms\n",
      "Speed: 1.2ms preprocess, 626.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 2 trucks, 628.2ms\n",
      "Speed: 1.2ms preprocess, 628.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 truck, 633.2ms\n",
      "Speed: 1.2ms preprocess, 633.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 8 cars, 1 truck, 631.0ms\n",
      "Speed: 1.2ms preprocess, 631.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 2 trucks, 644.2ms\n",
      "Speed: 1.5ms preprocess, 644.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 631.9ms\n",
      "Speed: 1.9ms preprocess, 631.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 636.4ms\n",
      "Speed: 1.8ms preprocess, 636.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 637.2ms\n",
      "Speed: 1.8ms preprocess, 637.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 632.3ms\n",
      "Speed: 1.2ms preprocess, 632.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 624.4ms\n",
      "Speed: 1.2ms preprocess, 624.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 633.3ms\n",
      "Speed: 1.2ms preprocess, 633.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 628.2ms\n",
      "Speed: 1.7ms preprocess, 628.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 641.7ms\n",
      "Speed: 1.7ms preprocess, 641.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 635.0ms\n",
      "Speed: 1.2ms preprocess, 635.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 635.7ms\n",
      "Speed: 1.2ms preprocess, 635.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 636.8ms\n",
      "Speed: 2.1ms preprocess, 636.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 638.7ms\n",
      "Speed: 1.2ms preprocess, 638.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 633.0ms\n",
      "Speed: 1.2ms preprocess, 633.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 643.7ms\n",
      "Speed: 1.2ms preprocess, 643.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 633.7ms\n",
      "Speed: 1.9ms preprocess, 633.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 637.1ms\n",
      "Speed: 1.2ms preprocess, 637.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 627.7ms\n",
      "Speed: 1.8ms preprocess, 627.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 632.7ms\n",
      "Speed: 1.2ms preprocess, 632.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 629.9ms\n",
      "Speed: 1.2ms preprocess, 629.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 629.2ms\n",
      "Speed: 1.2ms preprocess, 629.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 627.9ms\n",
      "Speed: 1.2ms preprocess, 627.9ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 637.5ms\n",
      "Speed: 1.5ms preprocess, 637.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 624.4ms\n",
      "Speed: 1.2ms preprocess, 624.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 637.1ms\n",
      "Speed: 1.2ms preprocess, 637.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 638.2ms\n",
      "Speed: 1.7ms preprocess, 638.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 640.8ms\n",
      "Speed: 2.3ms preprocess, 640.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 truck, 1 traffic light, 635.8ms\n",
      "Speed: 1.6ms preprocess, 635.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 627.3ms\n",
      "Speed: 1.2ms preprocess, 627.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 627.8ms\n",
      "Speed: 1.2ms preprocess, 627.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 638.8ms\n",
      "Speed: 1.2ms preprocess, 638.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 640.2ms\n",
      "Speed: 1.2ms preprocess, 640.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 truck, 1 traffic light, 633.0ms\n",
      "Speed: 1.2ms preprocess, 633.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 641.5ms\n",
      "Speed: 1.3ms preprocess, 641.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 630.9ms\n",
      "Speed: 1.2ms preprocess, 630.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 624.7ms\n",
      "Speed: 1.8ms preprocess, 624.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 1 traffic light, 625.2ms\n",
      "Speed: 1.2ms preprocess, 625.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 634.2ms\n",
      "Speed: 1.2ms preprocess, 634.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 truck, 1 traffic light, 633.0ms\n",
      "Speed: 1.8ms preprocess, 633.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 626.5ms\n",
      "Speed: 1.8ms preprocess, 626.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 truck, 1 traffic light, 624.6ms\n",
      "Speed: 1.8ms preprocess, 624.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 632.0ms\n",
      "Speed: 1.1ms preprocess, 632.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 632.7ms\n",
      "Speed: 1.3ms preprocess, 632.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 645.5ms\n",
      "Speed: 1.2ms preprocess, 645.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 truck, 1 traffic light, 635.1ms\n",
      "Speed: 2.4ms preprocess, 635.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 truck, 1 traffic light, 626.1ms\n",
      "Speed: 1.2ms preprocess, 626.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 truck, 1 traffic light, 635.0ms\n",
      "Speed: 1.2ms preprocess, 635.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 628.7ms\n",
      "Speed: 1.8ms preprocess, 628.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 634.1ms\n",
      "Speed: 1.2ms preprocess, 634.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 632.7ms\n",
      "Speed: 1.4ms preprocess, 632.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 632.6ms\n",
      "Speed: 1.5ms preprocess, 632.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 644.1ms\n",
      "Speed: 1.8ms preprocess, 644.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 633.7ms\n",
      "Speed: 2.0ms preprocess, 633.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 631.2ms\n",
      "Speed: 1.1ms preprocess, 631.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 631.6ms\n",
      "Speed: 1.9ms preprocess, 631.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 635.8ms\n",
      "Speed: 1.9ms preprocess, 635.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 638.9ms\n",
      "Speed: 1.2ms preprocess, 638.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 645.9ms\n",
      "Speed: 1.2ms preprocess, 645.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 634.9ms\n",
      "Speed: 1.8ms preprocess, 634.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 637.4ms\n",
      "Speed: 1.7ms preprocess, 637.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 628.0ms\n",
      "Speed: 1.2ms preprocess, 628.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 635.7ms\n",
      "Speed: 1.2ms preprocess, 635.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 truck, 1 traffic light, 648.5ms\n",
      "Speed: 1.2ms preprocess, 648.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 traffic light, 649.3ms\n",
      "Speed: 1.2ms preprocess, 649.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 traffic light, 656.5ms\n",
      "Speed: 1.2ms preprocess, 656.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 traffic light, 643.4ms\n",
      "Speed: 1.9ms preprocess, 643.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 traffic light, 646.5ms\n",
      "Speed: 1.9ms preprocess, 646.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 648.8ms\n",
      "Speed: 1.6ms preprocess, 648.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 626.7ms\n",
      "Speed: 1.1ms preprocess, 626.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 618.6ms\n",
      "Speed: 1.7ms preprocess, 618.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 648.0ms\n",
      "Speed: 1.3ms preprocess, 648.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 640.8ms\n",
      "Speed: 1.8ms preprocess, 640.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 639.1ms\n",
      "Speed: 1.3ms preprocess, 639.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 642.7ms\n",
      "Speed: 2.2ms preprocess, 642.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 641.5ms\n",
      "Speed: 1.6ms preprocess, 641.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 644.5ms\n",
      "Speed: 1.2ms preprocess, 644.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 651.7ms\n",
      "Speed: 1.2ms preprocess, 651.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 644.2ms\n",
      "Speed: 1.2ms preprocess, 644.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 641.2ms\n",
      "Speed: 1.8ms preprocess, 641.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 639.7ms\n",
      "Speed: 1.2ms preprocess, 639.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 646.6ms\n",
      "Speed: 1.9ms preprocess, 646.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 641.9ms\n",
      "Speed: 1.2ms preprocess, 641.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 644.4ms\n",
      "Speed: 1.2ms preprocess, 644.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 641.1ms\n",
      "Speed: 1.2ms preprocess, 641.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 644.0ms\n",
      "Speed: 1.2ms preprocess, 644.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 639.0ms\n",
      "Speed: 1.2ms preprocess, 639.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 647.9ms\n",
      "Speed: 1.2ms preprocess, 647.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 639.0ms\n",
      "Speed: 1.9ms preprocess, 639.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 637.6ms\n",
      "Speed: 1.9ms preprocess, 637.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 634.4ms\n",
      "Speed: 1.2ms preprocess, 634.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 649.6ms\n",
      "Speed: 1.2ms preprocess, 649.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 638.5ms\n",
      "Speed: 1.2ms preprocess, 638.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 634.4ms\n",
      "Speed: 1.2ms preprocess, 634.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 641.3ms\n",
      "Speed: 1.2ms preprocess, 641.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 644.0ms\n",
      "Speed: 1.2ms preprocess, 644.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 639.8ms\n",
      "Speed: 1.2ms preprocess, 639.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 643.2ms\n",
      "Speed: 1.8ms preprocess, 643.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 643.1ms\n",
      "Speed: 1.2ms preprocess, 643.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 636.8ms\n",
      "Speed: 1.2ms preprocess, 636.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 traffic light, 641.6ms\n",
      "Speed: 1.8ms preprocess, 641.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 truck, 1 traffic light, 638.0ms\n",
      "Speed: 1.9ms preprocess, 638.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 641.3ms\n",
      "Speed: 1.1ms preprocess, 641.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 633.7ms\n",
      "Speed: 1.1ms preprocess, 633.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 634.4ms\n",
      "Speed: 1.9ms preprocess, 634.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 652.6ms\n",
      "Speed: 1.8ms preprocess, 652.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 645.3ms\n",
      "Speed: 1.6ms preprocess, 645.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 641.6ms\n",
      "Speed: 1.2ms preprocess, 641.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 629.7ms\n",
      "Speed: 1.9ms preprocess, 629.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 637.2ms\n",
      "Speed: 1.2ms preprocess, 637.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 632.4ms\n",
      "Speed: 1.2ms preprocess, 632.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 625.6ms\n",
      "Speed: 1.2ms preprocess, 625.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 632.7ms\n",
      "Speed: 1.2ms preprocess, 632.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 639.2ms\n",
      "Speed: 1.2ms preprocess, 639.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 635.0ms\n",
      "Speed: 1.7ms preprocess, 635.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 628.3ms\n",
      "Speed: 1.2ms preprocess, 628.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 628.8ms\n",
      "Speed: 1.2ms preprocess, 628.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 traffic light, 630.7ms\n",
      "Speed: 1.2ms preprocess, 630.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 traffic light, 634.6ms\n",
      "Speed: 1.2ms preprocess, 634.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 traffic light, 642.0ms\n",
      "Speed: 1.2ms preprocess, 642.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 traffic light, 633.6ms\n",
      "Speed: 1.2ms preprocess, 633.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 634.1ms\n",
      "Speed: 1.2ms preprocess, 634.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 1 traffic light, 628.3ms\n",
      "Speed: 1.9ms preprocess, 628.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 traffic light, 631.7ms\n",
      "Speed: 1.9ms preprocess, 631.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 motorcycle, 1 traffic light, 643.5ms\n",
      "Speed: 1.2ms preprocess, 643.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 motorcycle, 1 traffic light, 633.0ms\n",
      "Speed: 1.8ms preprocess, 633.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 motorcycle, 1 traffic light, 651.6ms\n",
      "Speed: 1.8ms preprocess, 651.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 motorcycle, 1 traffic light, 643.5ms\n",
      "Speed: 1.2ms preprocess, 643.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 motorcycle, 1 traffic light, 634.7ms\n",
      "Speed: 1.8ms preprocess, 634.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 motorcycle, 1 traffic light, 637.8ms\n",
      "Speed: 1.7ms preprocess, 637.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 motorcycle, 1 traffic light, 638.3ms\n",
      "Speed: 1.2ms preprocess, 638.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 7 cars, 1 motorcycle, 1 traffic light, 635.2ms\n",
      "Speed: 1.4ms preprocess, 635.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 633.2ms\n",
      "Speed: 1.5ms preprocess, 633.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 647.5ms\n",
      "Speed: 1.2ms preprocess, 647.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 638.2ms\n",
      "Speed: 1.2ms preprocess, 638.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 624.6ms\n",
      "Speed: 1.2ms preprocess, 624.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 631.9ms\n",
      "Speed: 1.1ms preprocess, 631.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 635.5ms\n",
      "Speed: 1.9ms preprocess, 635.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 645.6ms\n",
      "Speed: 1.1ms preprocess, 645.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 633.6ms\n",
      "Speed: 1.7ms preprocess, 633.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 645.6ms\n",
      "Speed: 1.2ms preprocess, 645.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 639.6ms\n",
      "Speed: 1.9ms preprocess, 639.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 636.9ms\n",
      "Speed: 1.9ms preprocess, 636.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 634.3ms\n",
      "Speed: 1.2ms preprocess, 634.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 1 traffic light, 630.8ms\n",
      "Speed: 1.2ms preprocess, 630.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 638.6ms\n",
      "Speed: 1.6ms preprocess, 638.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 634.6ms\n",
      "Speed: 1.2ms preprocess, 634.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 646.2ms\n",
      "Speed: 1.5ms preprocess, 646.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 641.4ms\n",
      "Speed: 1.2ms preprocess, 641.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 672.9ms\n",
      "Speed: 1.2ms preprocess, 672.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 624.5ms\n",
      "Speed: 1.2ms preprocess, 624.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 644.6ms\n",
      "Speed: 1.2ms preprocess, 644.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 646.2ms\n",
      "Speed: 1.2ms preprocess, 646.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 637.9ms\n",
      "Speed: 1.9ms preprocess, 637.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 650.3ms\n",
      "Speed: 1.9ms preprocess, 650.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 642.9ms\n",
      "Speed: 1.2ms preprocess, 642.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 6 cars, 1 motorcycle, 642.2ms\n",
      "Speed: 1.9ms preprocess, 642.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 motorcycle, 643.3ms\n",
      "Speed: 1.2ms preprocess, 643.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 6 cars, 649.6ms\n",
      "Speed: 1.2ms preprocess, 649.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 6 cars, 1 traffic light, 643.7ms\n",
      "Speed: 1.6ms preprocess, 643.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 6 cars, 1 traffic light, 639.9ms\n",
      "Speed: 1.2ms preprocess, 639.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 6 cars, 1 traffic light, 638.7ms\n",
      "Speed: 1.7ms preprocess, 638.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 640.4ms\n",
      "Speed: 1.7ms preprocess, 640.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 634.0ms\n",
      "Speed: 1.2ms preprocess, 634.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 traffic light, 641.8ms\n",
      "Speed: 1.2ms preprocess, 641.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 635.0ms\n",
      "Speed: 1.2ms preprocess, 635.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 634.0ms\n",
      "Speed: 1.6ms preprocess, 634.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 648.3ms\n",
      "Speed: 1.7ms preprocess, 648.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 635.6ms\n",
      "Speed: 1.2ms preprocess, 635.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 643.2ms\n",
      "Speed: 1.8ms preprocess, 643.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 651.1ms\n",
      "Speed: 1.4ms preprocess, 651.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 650.4ms\n",
      "Speed: 1.2ms preprocess, 650.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 631.3ms\n",
      "Speed: 1.9ms preprocess, 631.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 653.7ms\n",
      "Speed: 1.2ms preprocess, 653.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 650.1ms\n",
      "Speed: 1.8ms preprocess, 650.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 630.2ms\n",
      "Speed: 1.9ms preprocess, 630.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 625.7ms\n",
      "Speed: 2.0ms preprocess, 625.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 632.9ms\n",
      "Speed: 1.7ms preprocess, 632.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 1 traffic light, 632.4ms\n",
      "Speed: 1.2ms preprocess, 632.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 1 traffic light, 634.9ms\n",
      "Speed: 1.5ms preprocess, 634.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 traffic light, 631.6ms\n",
      "Speed: 1.2ms preprocess, 631.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 traffic light, 632.9ms\n",
      "Speed: 1.2ms preprocess, 632.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 1 traffic light, 632.5ms\n",
      "Speed: 1.4ms preprocess, 632.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 traffic light, 639.5ms\n",
      "Speed: 1.4ms preprocess, 639.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 1 traffic light, 651.8ms\n",
      "Speed: 1.2ms preprocess, 651.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 traffic light, 642.1ms\n",
      "Speed: 1.8ms preprocess, 642.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 traffic light, 645.9ms\n",
      "Speed: 1.2ms preprocess, 645.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 traffic light, 640.2ms\n",
      "Speed: 1.2ms preprocess, 640.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 traffic light, 634.2ms\n",
      "Speed: 1.2ms preprocess, 634.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 traffic light, 634.6ms\n",
      "Speed: 1.9ms preprocess, 634.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 traffic light, 636.9ms\n",
      "Speed: 1.2ms preprocess, 636.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 638.7ms\n",
      "Speed: 1.2ms preprocess, 638.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 646.1ms\n",
      "Speed: 1.9ms preprocess, 646.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 motorcycles, 1 traffic light, 638.6ms\n",
      "Speed: 1.9ms preprocess, 638.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 643.2ms\n",
      "Speed: 2.0ms preprocess, 643.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 motorcycles, 1 traffic light, 634.6ms\n",
      "Speed: 1.2ms preprocess, 634.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 642.6ms\n",
      "Speed: 1.4ms preprocess, 642.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 motorcycles, 1 traffic light, 627.7ms\n",
      "Speed: 1.6ms preprocess, 627.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 634.4ms\n",
      "Speed: 1.6ms preprocess, 634.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 636.2ms\n",
      "Speed: 1.7ms preprocess, 636.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 motorcycles, 1 traffic light, 635.2ms\n",
      "Speed: 1.2ms preprocess, 635.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 645.0ms\n",
      "Speed: 1.2ms preprocess, 645.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 638.0ms\n",
      "Speed: 1.6ms preprocess, 638.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 640.1ms\n",
      "Speed: 1.4ms preprocess, 640.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 636.4ms\n",
      "Speed: 1.7ms preprocess, 636.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 650.1ms\n",
      "Speed: 1.2ms preprocess, 650.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 653.6ms\n",
      "Speed: 1.7ms preprocess, 653.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 2 motorcycles, 1 traffic light, 634.9ms\n",
      "Speed: 1.2ms preprocess, 634.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 648.1ms\n",
      "Speed: 1.4ms preprocess, 648.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 629.2ms\n",
      "Speed: 2.0ms preprocess, 629.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 638.9ms\n",
      "Speed: 1.8ms preprocess, 638.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 motorcycle, 637.9ms\n",
      "Speed: 1.2ms preprocess, 637.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 motorcycle, 632.9ms\n",
      "Speed: 1.2ms preprocess, 632.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 627.2ms\n",
      "Speed: 1.7ms preprocess, 627.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 635.1ms\n",
      "Speed: 1.2ms preprocess, 635.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 632.6ms\n",
      "Speed: 1.7ms preprocess, 632.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 644.0ms\n",
      "Speed: 1.7ms preprocess, 644.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 639.8ms\n",
      "Speed: 1.8ms preprocess, 639.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 633.9ms\n",
      "Speed: 1.2ms preprocess, 633.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 637.8ms\n",
      "Speed: 1.2ms preprocess, 637.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 644.3ms\n",
      "Speed: 1.2ms preprocess, 644.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 633.0ms\n",
      "Speed: 1.9ms preprocess, 633.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 648.1ms\n",
      "Speed: 1.8ms preprocess, 648.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 640.3ms\n",
      "Speed: 1.9ms preprocess, 640.3ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 644.0ms\n",
      "Speed: 1.9ms preprocess, 644.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 639.8ms\n",
      "Speed: 1.5ms preprocess, 639.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 638.4ms\n",
      "Speed: 1.2ms preprocess, 638.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 654.4ms\n",
      "Speed: 1.8ms preprocess, 654.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 638.1ms\n",
      "Speed: 1.2ms preprocess, 638.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 657.8ms\n",
      "Speed: 1.2ms preprocess, 657.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 609.6ms\n",
      "Speed: 1.4ms preprocess, 609.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 635.8ms\n",
      "Speed: 1.2ms preprocess, 635.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 traffic light, 632.3ms\n",
      "Speed: 1.2ms preprocess, 632.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 640.5ms\n",
      "Speed: 1.6ms preprocess, 640.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 646.4ms\n",
      "Speed: 2.2ms preprocess, 646.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 651.6ms\n",
      "Speed: 1.7ms preprocess, 651.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 635.8ms\n",
      "Speed: 1.2ms preprocess, 635.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 634.6ms\n",
      "Speed: 1.2ms preprocess, 634.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 646.1ms\n",
      "Speed: 1.4ms preprocess, 646.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 649.4ms\n",
      "Speed: 1.9ms preprocess, 649.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 632.8ms\n",
      "Speed: 2.0ms preprocess, 632.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 640.8ms\n",
      "Speed: 2.0ms preprocess, 640.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 638.2ms\n",
      "Speed: 1.2ms preprocess, 638.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 639.2ms\n",
      "Speed: 1.9ms preprocess, 639.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 636.2ms\n",
      "Speed: 2.0ms preprocess, 636.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 640.2ms\n",
      "Speed: 1.2ms preprocess, 640.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 636.2ms\n",
      "Speed: 1.6ms preprocess, 636.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 638.1ms\n",
      "Speed: 1.8ms preprocess, 638.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 637.5ms\n",
      "Speed: 1.3ms preprocess, 637.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 642.3ms\n",
      "Speed: 1.7ms preprocess, 642.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 bus, 645.2ms\n",
      "Speed: 2.2ms preprocess, 645.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 641.7ms\n",
      "Speed: 1.6ms preprocess, 641.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 638.3ms\n",
      "Speed: 1.2ms preprocess, 638.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 636.2ms\n",
      "Speed: 1.2ms preprocess, 636.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 639.7ms\n",
      "Speed: 1.2ms preprocess, 639.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 638.8ms\n",
      "Speed: 1.2ms preprocess, 638.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 640.6ms\n",
      "Speed: 1.9ms preprocess, 640.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 644.4ms\n",
      "Speed: 1.9ms preprocess, 644.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 639.5ms\n",
      "Speed: 1.9ms preprocess, 639.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 632.9ms\n",
      "Speed: 1.2ms preprocess, 632.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 647.0ms\n",
      "Speed: 1.2ms preprocess, 647.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 643.7ms\n",
      "Speed: 1.5ms preprocess, 643.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 638.3ms\n",
      "Speed: 1.2ms preprocess, 638.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 644.4ms\n",
      "Speed: 1.5ms preprocess, 644.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 645.8ms\n",
      "Speed: 1.9ms preprocess, 645.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 638.6ms\n",
      "Speed: 1.5ms preprocess, 638.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 633.8ms\n",
      "Speed: 1.8ms preprocess, 633.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 626.9ms\n",
      "Speed: 1.4ms preprocess, 626.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 644.0ms\n",
      "Speed: 1.3ms preprocess, 644.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 642.8ms\n",
      "Speed: 1.2ms preprocess, 642.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 traffic light, 637.2ms\n",
      "Speed: 1.4ms preprocess, 637.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 633.5ms\n",
      "Speed: 1.4ms preprocess, 633.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 638.2ms\n",
      "Speed: 1.7ms preprocess, 638.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 traffic light, 637.7ms\n",
      "Speed: 1.2ms preprocess, 637.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 639.2ms\n",
      "Speed: 1.7ms preprocess, 639.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 638.8ms\n",
      "Speed: 1.3ms preprocess, 638.8ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 truck, 1 traffic light, 634.7ms\n",
      "Speed: 1.9ms preprocess, 634.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 641.8ms\n",
      "Speed: 2.0ms preprocess, 641.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 traffic light, 643.3ms\n",
      "Speed: 2.0ms preprocess, 643.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 641.0ms\n",
      "Speed: 1.2ms preprocess, 641.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 639.3ms\n",
      "Speed: 1.2ms preprocess, 639.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 traffic light, 644.3ms\n",
      "Speed: 1.6ms preprocess, 644.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 traffic light, 641.8ms\n",
      "Speed: 1.9ms preprocess, 641.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 traffic light, 638.9ms\n",
      "Speed: 1.7ms preprocess, 638.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 cars, 1 motorcycle, 1 traffic light, 628.8ms\n",
      "Speed: 1.2ms preprocess, 628.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 641.4ms\n",
      "Speed: 1.2ms preprocess, 641.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 640.4ms\n",
      "Speed: 1.3ms preprocess, 640.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 647.9ms\n",
      "Speed: 1.1ms preprocess, 647.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 651.0ms\n",
      "Speed: 1.7ms preprocess, 651.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 2 trucks, 643.4ms\n",
      "Speed: 1.3ms preprocess, 643.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 659.3ms\n",
      "Speed: 1.4ms preprocess, 659.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 643.9ms\n",
      "Speed: 1.2ms preprocess, 643.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 643.1ms\n",
      "Speed: 2.0ms preprocess, 643.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 638.4ms\n",
      "Speed: 1.2ms preprocess, 638.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 627.6ms\n",
      "Speed: 1.9ms preprocess, 627.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 646.0ms\n",
      "Speed: 1.2ms preprocess, 646.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 640.3ms\n",
      "Speed: 1.9ms preprocess, 640.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 2 trucks, 636.5ms\n",
      "Speed: 1.9ms preprocess, 636.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 629.8ms\n",
      "Speed: 1.9ms preprocess, 629.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 634.7ms\n",
      "Speed: 1.6ms preprocess, 634.7ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 648.5ms\n",
      "Speed: 1.5ms preprocess, 648.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 truck, 632.5ms\n",
      "Speed: 1.6ms preprocess, 632.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 motorcycle, 632.8ms\n",
      "Speed: 1.2ms preprocess, 632.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 2 trucks, 1 traffic light, 637.5ms\n",
      "Speed: 1.2ms preprocess, 637.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 truck, 1 traffic light, 621.3ms\n",
      "Speed: 1.9ms preprocess, 621.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 truck, 1 traffic light, 632.4ms\n",
      "Speed: 1.2ms preprocess, 632.4ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 motorcycle, 1 traffic light, 634.0ms\n",
      "Speed: 1.8ms preprocess, 634.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 motorcycle, 1 traffic light, 643.7ms\n",
      "Speed: 1.2ms preprocess, 643.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 motorcycle, 1 traffic light, 642.4ms\n",
      "Speed: 1.9ms preprocess, 642.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 motorcycle, 1 traffic light, 621.0ms\n",
      "Speed: 1.1ms preprocess, 621.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 622.8ms\n",
      "Speed: 1.1ms preprocess, 622.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 629.9ms\n",
      "Speed: 1.2ms preprocess, 629.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 643.2ms\n",
      "Speed: 1.2ms preprocess, 643.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 639.4ms\n",
      "Speed: 1.3ms preprocess, 639.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 649.5ms\n",
      "Speed: 2.0ms preprocess, 649.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 641.1ms\n",
      "Speed: 1.5ms preprocess, 641.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 635.5ms\n",
      "Speed: 1.3ms preprocess, 635.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 637.3ms\n",
      "Speed: 1.3ms preprocess, 637.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 644.8ms\n",
      "Speed: 1.6ms preprocess, 644.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 637.3ms\n",
      "Speed: 1.4ms preprocess, 637.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 1 traffic light, 628.1ms\n",
      "Speed: 2.2ms preprocess, 628.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 639.8ms\n",
      "Speed: 1.5ms preprocess, 639.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 638.0ms\n",
      "Speed: 1.6ms preprocess, 638.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 633.0ms\n",
      "Speed: 1.7ms preprocess, 633.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 643.7ms\n",
      "Speed: 1.2ms preprocess, 643.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 633.4ms\n",
      "Speed: 1.4ms preprocess, 633.4ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 639.6ms\n",
      "Speed: 1.2ms preprocess, 639.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 643.6ms\n",
      "Speed: 1.4ms preprocess, 643.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 640.8ms\n",
      "Speed: 1.4ms preprocess, 640.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 639.8ms\n",
      "Speed: 1.2ms preprocess, 639.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 643.2ms\n",
      "Speed: 1.8ms preprocess, 643.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 642.0ms\n",
      "Speed: 1.3ms preprocess, 642.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 643.8ms\n",
      "Speed: 1.2ms preprocess, 643.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 635.5ms\n",
      "Speed: 1.9ms preprocess, 635.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 636.9ms\n",
      "Speed: 1.2ms preprocess, 636.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 636.9ms\n",
      "Speed: 1.6ms preprocess, 636.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 642.5ms\n",
      "Speed: 1.7ms preprocess, 642.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 637.6ms\n",
      "Speed: 1.9ms preprocess, 637.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 635.6ms\n",
      "Speed: 1.2ms preprocess, 635.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 640.1ms\n",
      "Speed: 1.2ms preprocess, 640.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 641.1ms\n",
      "Speed: 1.7ms preprocess, 641.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 638.0ms\n",
      "Speed: 1.3ms preprocess, 638.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 643.9ms\n",
      "Speed: 1.2ms preprocess, 643.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 640.9ms\n",
      "Speed: 1.2ms preprocess, 640.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 641.2ms\n",
      "Speed: 1.1ms preprocess, 641.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 640.9ms\n",
      "Speed: 1.2ms preprocess, 640.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 652.3ms\n",
      "Speed: 1.8ms preprocess, 652.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 642.6ms\n",
      "Speed: 1.6ms preprocess, 642.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 641.5ms\n",
      "Speed: 1.2ms preprocess, 641.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 642.6ms\n",
      "Speed: 2.0ms preprocess, 642.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 634.5ms\n",
      "Speed: 1.2ms preprocess, 634.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 634.4ms\n",
      "Speed: 1.9ms preprocess, 634.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 638.2ms\n",
      "Speed: 1.5ms preprocess, 638.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 632.5ms\n",
      "Speed: 1.2ms preprocess, 632.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 649.5ms\n",
      "Speed: 1.3ms preprocess, 649.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 641.6ms\n",
      "Speed: 1.7ms preprocess, 641.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 1 motorcycle, 638.7ms\n",
      "Speed: 1.2ms preprocess, 638.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 641.7ms\n",
      "Speed: 1.2ms preprocess, 641.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 643.6ms\n",
      "Speed: 1.7ms preprocess, 643.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 640.9ms\n",
      "Speed: 1.5ms preprocess, 640.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 642.4ms\n",
      "Speed: 1.2ms preprocess, 642.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 637.8ms\n",
      "Speed: 1.2ms preprocess, 637.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 638.5ms\n",
      "Speed: 1.9ms preprocess, 638.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 632.2ms\n",
      "Speed: 1.2ms preprocess, 632.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 647.9ms\n",
      "Speed: 1.9ms preprocess, 647.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 641.1ms\n",
      "Speed: 1.9ms preprocess, 641.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 627.2ms\n",
      "Speed: 1.2ms preprocess, 627.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 641.8ms\n",
      "Speed: 1.2ms preprocess, 641.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 641.3ms\n",
      "Speed: 1.2ms preprocess, 641.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 640.4ms\n",
      "Speed: 1.2ms preprocess, 640.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 645.7ms\n",
      "Speed: 1.7ms preprocess, 645.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 640.8ms\n",
      "Speed: 1.5ms preprocess, 640.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 627.0ms\n",
      "Speed: 1.8ms preprocess, 627.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 625.0ms\n",
      "Speed: 1.5ms preprocess, 625.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 635.9ms\n",
      "Speed: 1.5ms preprocess, 635.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 632.2ms\n",
      "Speed: 1.7ms preprocess, 632.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 641.9ms\n",
      "Speed: 1.2ms preprocess, 641.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 traffic light, 627.7ms\n",
      "Speed: 1.6ms preprocess, 627.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 624.9ms\n",
      "Speed: 1.2ms preprocess, 624.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 639.4ms\n",
      "Speed: 1.8ms preprocess, 639.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 634.9ms\n",
      "Speed: 1.2ms preprocess, 634.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 643.1ms\n",
      "Speed: 1.2ms preprocess, 643.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 639.9ms\n",
      "Speed: 1.2ms preprocess, 639.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 647.6ms\n",
      "Speed: 1.2ms preprocess, 647.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 646.5ms\n",
      "Speed: 2.0ms preprocess, 646.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 633.0ms\n",
      "Speed: 1.8ms preprocess, 633.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 646.4ms\n",
      "Speed: 1.9ms preprocess, 646.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 642.3ms\n",
      "Speed: 1.2ms preprocess, 642.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 651.8ms\n",
      "Speed: 1.3ms preprocess, 651.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 611.2ms\n",
      "Speed: 1.6ms preprocess, 611.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 621.6ms\n",
      "Speed: 1.7ms preprocess, 621.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 623.6ms\n",
      "Speed: 1.2ms preprocess, 623.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 625.0ms\n",
      "Speed: 1.6ms preprocess, 625.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 624.3ms\n",
      "Speed: 1.5ms preprocess, 624.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 629.6ms\n",
      "Speed: 1.7ms preprocess, 629.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 652.8ms\n",
      "Speed: 1.2ms preprocess, 652.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 639.0ms\n",
      "Speed: 1.2ms preprocess, 639.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 645.1ms\n",
      "Speed: 1.2ms preprocess, 645.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 639.3ms\n",
      "Speed: 1.4ms preprocess, 639.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 643.9ms\n",
      "Speed: 1.3ms preprocess, 643.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 640.8ms\n",
      "Speed: 1.2ms preprocess, 640.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 1 traffic light, 633.6ms\n",
      "Speed: 1.2ms preprocess, 633.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 2 trucks, 1 traffic light, 642.8ms\n",
      "Speed: 1.2ms preprocess, 642.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 bus, 1 truck, 643.2ms\n",
      "Speed: 1.2ms preprocess, 643.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 641.0ms\n",
      "Speed: 1.2ms preprocess, 641.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 649.3ms\n",
      "Speed: 1.2ms preprocess, 649.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 635.8ms\n",
      "Speed: 1.4ms preprocess, 635.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 632.0ms\n",
      "Speed: 1.8ms preprocess, 632.0ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 4 cars, 1 motorcycle, 1 truck, 639.6ms\n",
      "Speed: 1.2ms preprocess, 639.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 634.1ms\n",
      "Speed: 1.2ms preprocess, 634.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 632.8ms\n",
      "Speed: 1.2ms preprocess, 632.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 657.3ms\n",
      "Speed: 1.3ms preprocess, 657.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 631.9ms\n",
      "Speed: 1.3ms preprocess, 631.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 637.7ms\n",
      "Speed: 1.5ms preprocess, 637.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 632.7ms\n",
      "Speed: 2.0ms preprocess, 632.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 638.7ms\n",
      "Speed: 1.9ms preprocess, 638.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 640.9ms\n",
      "Speed: 2.0ms preprocess, 640.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 639.6ms\n",
      "Speed: 1.9ms preprocess, 639.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 635.5ms\n",
      "Speed: 2.1ms preprocess, 635.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 669.6ms\n",
      "Speed: 2.0ms preprocess, 669.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 660.2ms\n",
      "Speed: 1.9ms preprocess, 660.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 664.2ms\n",
      "Speed: 1.2ms preprocess, 664.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 672.5ms\n",
      "Speed: 1.8ms preprocess, 672.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 696.3ms\n",
      "Speed: 2.1ms preprocess, 696.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 667.8ms\n",
      "Speed: 2.2ms preprocess, 667.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 658.9ms\n",
      "Speed: 1.6ms preprocess, 658.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 666.5ms\n",
      "Speed: 1.2ms preprocess, 666.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 663.6ms\n",
      "Speed: 1.2ms preprocess, 663.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 664.0ms\n",
      "Speed: 1.3ms preprocess, 664.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 651.7ms\n",
      "Speed: 1.4ms preprocess, 651.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 657.4ms\n",
      "Speed: 1.2ms preprocess, 657.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 675.1ms\n",
      "Speed: 1.2ms preprocess, 675.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 669.7ms\n",
      "Speed: 1.2ms preprocess, 669.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 661.8ms\n",
      "Speed: 1.3ms preprocess, 661.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 658.3ms\n",
      "Speed: 1.5ms preprocess, 658.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 671.9ms\n",
      "Speed: 1.2ms preprocess, 671.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 651.6ms\n",
      "Speed: 1.2ms preprocess, 651.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 644.3ms\n",
      "Speed: 1.3ms preprocess, 644.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 649.1ms\n",
      "Speed: 1.1ms preprocess, 649.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 638.3ms\n",
      "Speed: 1.5ms preprocess, 638.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 647.0ms\n",
      "Speed: 1.2ms preprocess, 647.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 647.4ms\n",
      "Speed: 1.8ms preprocess, 647.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 644.2ms\n",
      "Speed: 1.2ms preprocess, 644.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 637.2ms\n",
      "Speed: 1.4ms preprocess, 637.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 642.1ms\n",
      "Speed: 1.2ms preprocess, 642.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 640.6ms\n",
      "Speed: 1.7ms preprocess, 640.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 656.2ms\n",
      "Speed: 1.9ms preprocess, 656.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 657.5ms\n",
      "Speed: 1.2ms preprocess, 657.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 639.8ms\n",
      "Speed: 1.2ms preprocess, 639.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 641.0ms\n",
      "Speed: 1.2ms preprocess, 641.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 636.1ms\n",
      "Speed: 1.2ms preprocess, 636.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 638.9ms\n",
      "Speed: 1.2ms preprocess, 638.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 633.2ms\n",
      "Speed: 1.6ms preprocess, 633.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 646.6ms\n",
      "Speed: 1.2ms preprocess, 646.6ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 644.7ms\n",
      "Speed: 1.2ms preprocess, 644.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 643.8ms\n",
      "Speed: 1.4ms preprocess, 643.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 642.9ms\n",
      "Speed: 1.8ms preprocess, 642.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 647.2ms\n",
      "Speed: 1.6ms preprocess, 647.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 649.0ms\n",
      "Speed: 1.2ms preprocess, 649.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 647.5ms\n",
      "Speed: 1.4ms preprocess, 647.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 645.1ms\n",
      "Speed: 1.9ms preprocess, 645.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 648.1ms\n",
      "Speed: 1.2ms preprocess, 648.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 649.8ms\n",
      "Speed: 1.1ms preprocess, 649.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 655.1ms\n",
      "Speed: 1.2ms preprocess, 655.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 650.0ms\n",
      "Speed: 1.2ms preprocess, 650.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 653.5ms\n",
      "Speed: 1.2ms preprocess, 653.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 648.0ms\n",
      "Speed: 1.2ms preprocess, 648.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 646.5ms\n",
      "Speed: 1.2ms preprocess, 646.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 motorcycle, 1 truck, 1 traffic light, 630.8ms\n",
      "Speed: 1.7ms preprocess, 630.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 611.1ms\n",
      "Speed: 1.5ms preprocess, 611.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 653.6ms\n",
      "Speed: 1.2ms preprocess, 653.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 motorcycle, 1 truck, 1 traffic light, 658.7ms\n",
      "Speed: 1.9ms preprocess, 658.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 motorcycle, 1 truck, 1 traffic light, 660.0ms\n",
      "Speed: 1.2ms preprocess, 660.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 motorcycle, 1 truck, 1 traffic light, 661.3ms\n",
      "Speed: 2.1ms preprocess, 661.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 motorcycle, 1 truck, 1 traffic light, 648.2ms\n",
      "Speed: 1.2ms preprocess, 648.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 motorcycle, 1 truck, 1 traffic light, 659.5ms\n",
      "Speed: 1.9ms preprocess, 659.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 motorcycle, 1 truck, 1 traffic light, 670.1ms\n",
      "Speed: 1.5ms preprocess, 670.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 motorcycle, 1 truck, 1 traffic light, 648.0ms\n",
      "Speed: 1.2ms preprocess, 648.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 1 motorcycle, 1 truck, 1 traffic light, 643.2ms\n",
      "Speed: 1.2ms preprocess, 643.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 644.8ms\n",
      "Speed: 1.4ms preprocess, 644.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 647.6ms\n",
      "Speed: 1.9ms preprocess, 647.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 684.4ms\n",
      "Speed: 2.0ms preprocess, 684.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 669.9ms\n",
      "Speed: 1.3ms preprocess, 669.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 640.6ms\n",
      "Speed: 1.1ms preprocess, 640.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 650.0ms\n",
      "Speed: 1.3ms preprocess, 650.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 667.5ms\n",
      "Speed: 1.2ms preprocess, 667.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 688.2ms\n",
      "Speed: 1.1ms preprocess, 688.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 642.1ms\n",
      "Speed: 1.2ms preprocess, 642.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 2 cars, 2 motorcycles, 1 truck, 611.2ms\n",
      "Speed: 1.1ms preprocess, 611.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 660.2ms\n",
      "Speed: 1.1ms preprocess, 660.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 652.5ms\n",
      "Speed: 1.9ms preprocess, 652.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 654.9ms\n",
      "Speed: 1.2ms preprocess, 654.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 670.7ms\n",
      "Speed: 1.3ms preprocess, 670.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 656.9ms\n",
      "Speed: 1.5ms preprocess, 656.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 656.6ms\n",
      "Speed: 1.2ms preprocess, 656.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 660.1ms\n",
      "Speed: 2.2ms preprocess, 660.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 truck, 686.8ms\n",
      "Speed: 2.0ms preprocess, 686.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 672.6ms\n",
      "Speed: 2.1ms preprocess, 672.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 665.3ms\n",
      "Speed: 1.2ms preprocess, 665.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 664.2ms\n",
      "Speed: 1.9ms preprocess, 664.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 659.9ms\n",
      "Speed: 1.3ms preprocess, 659.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 676.6ms\n",
      "Speed: 1.2ms preprocess, 676.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 679.9ms\n",
      "Speed: 1.3ms preprocess, 679.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 677.7ms\n",
      "Speed: 1.4ms preprocess, 677.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 668.6ms\n",
      "Speed: 1.4ms preprocess, 668.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 667.5ms\n",
      "Speed: 1.2ms preprocess, 667.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 678.2ms\n",
      "Speed: 1.5ms preprocess, 678.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 688.2ms\n",
      "Speed: 1.7ms preprocess, 688.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 673.4ms\n",
      "Speed: 1.7ms preprocess, 673.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 644.7ms\n",
      "Speed: 1.6ms preprocess, 644.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 645.6ms\n",
      "Speed: 1.2ms preprocess, 645.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 659.1ms\n",
      "Speed: 1.5ms preprocess, 659.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 669.7ms\n",
      "Speed: 1.2ms preprocess, 669.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 660.3ms\n",
      "Speed: 1.4ms preprocess, 660.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 652.6ms\n",
      "Speed: 1.9ms preprocess, 652.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 648.6ms\n",
      "Speed: 1.2ms preprocess, 648.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 655.5ms\n",
      "Speed: 1.2ms preprocess, 655.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 646.0ms\n",
      "Speed: 1.2ms preprocess, 646.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 662.7ms\n",
      "Speed: 1.2ms preprocess, 662.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 665.4ms\n",
      "Speed: 1.2ms preprocess, 665.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 671.2ms\n",
      "Speed: 1.4ms preprocess, 671.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 663.2ms\n",
      "Speed: 2.1ms preprocess, 663.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 bus, 1 traffic light, 654.4ms\n",
      "Speed: 1.9ms preprocess, 654.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 bus, 1 traffic light, 660.0ms\n",
      "Speed: 1.6ms preprocess, 660.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 657.4ms\n",
      "Speed: 1.3ms preprocess, 657.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 663.1ms\n",
      "Speed: 1.2ms preprocess, 663.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 659.4ms\n",
      "Speed: 1.9ms preprocess, 659.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 1 bus, 1 truck, 1 traffic light, 651.2ms\n",
      "Speed: 2.2ms preprocess, 651.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 660.9ms\n",
      "Speed: 1.2ms preprocess, 660.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 645.4ms\n",
      "Speed: 1.4ms preprocess, 645.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 660.5ms\n",
      "Speed: 1.5ms preprocess, 660.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 653.2ms\n",
      "Speed: 1.5ms preprocess, 653.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 2 cars, 1 motorcycle, 2 trucks, 1 traffic light, 655.9ms\n",
      "Speed: 1.3ms preprocess, 655.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 651.8ms\n",
      "Speed: 1.9ms preprocess, 651.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 bus, 1 traffic light, 633.6ms\n",
      "Speed: 1.2ms preprocess, 633.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 640.5ms\n",
      "Speed: 2.0ms preprocess, 640.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 motorcycle, 1 truck, 1 traffic light, 650.5ms\n",
      "Speed: 1.9ms preprocess, 650.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 670.7ms\n",
      "Speed: 2.0ms preprocess, 670.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 643.3ms\n",
      "Speed: 1.3ms preprocess, 643.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 648.9ms\n",
      "Speed: 1.6ms preprocess, 648.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 649.0ms\n",
      "Speed: 1.2ms preprocess, 649.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 1 truck, 1 traffic light, 655.6ms\n",
      "Speed: 1.3ms preprocess, 655.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 653.9ms\n",
      "Speed: 1.3ms preprocess, 653.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 653.6ms\n",
      "Speed: 1.5ms preprocess, 653.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 647.7ms\n",
      "Speed: 1.3ms preprocess, 647.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 659.4ms\n",
      "Speed: 1.8ms preprocess, 659.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 1 truck, 1 traffic light, 666.0ms\n",
      "Speed: 1.2ms preprocess, 666.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 1 truck, 1 traffic light, 637.5ms\n",
      "Speed: 1.2ms preprocess, 637.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 660.7ms\n",
      "Speed: 1.2ms preprocess, 660.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 658.9ms\n",
      "Speed: 1.9ms preprocess, 658.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 651.0ms\n",
      "Speed: 1.2ms preprocess, 651.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 657.5ms\n",
      "Speed: 1.6ms preprocess, 657.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 656.6ms\n",
      "Speed: 1.7ms preprocess, 656.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 motorcycle, 1 traffic light, 653.5ms\n",
      "Speed: 1.2ms preprocess, 653.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 motorcycle, 1 traffic light, 661.6ms\n",
      "Speed: 1.2ms preprocess, 661.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 641.8ms\n",
      "Speed: 1.6ms preprocess, 641.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 643.2ms\n",
      "Speed: 1.3ms preprocess, 643.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 643.7ms\n",
      "Speed: 1.2ms preprocess, 643.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 motorcycle, 1 traffic light, 668.4ms\n",
      "Speed: 1.1ms preprocess, 668.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 647.5ms\n",
      "Speed: 2.0ms preprocess, 647.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 665.8ms\n",
      "Speed: 1.5ms preprocess, 665.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 motorcycle, 1 traffic light, 664.9ms\n",
      "Speed: 1.2ms preprocess, 664.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 traffic light, 639.7ms\n",
      "Speed: 1.2ms preprocess, 639.7ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 motorcycle, 1 traffic light, 657.0ms\n",
      "Speed: 1.2ms preprocess, 657.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 motorcycle, 1 traffic light, 645.7ms\n",
      "Speed: 1.5ms preprocess, 645.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 637.4ms\n",
      "Speed: 1.8ms preprocess, 637.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 662.3ms\n",
      "Speed: 1.2ms preprocess, 662.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 646.8ms\n",
      "Speed: 1.5ms preprocess, 646.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 639.0ms\n",
      "Speed: 1.7ms preprocess, 639.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 650.4ms\n",
      "Speed: 1.2ms preprocess, 650.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 648.5ms\n",
      "Speed: 1.5ms preprocess, 648.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 655.4ms\n",
      "Speed: 1.2ms preprocess, 655.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 654.4ms\n",
      "Speed: 1.3ms preprocess, 654.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 652.9ms\n",
      "Speed: 1.8ms preprocess, 652.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 667.4ms\n",
      "Speed: 1.2ms preprocess, 667.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 659.1ms\n",
      "Speed: 1.3ms preprocess, 659.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 646.7ms\n",
      "Speed: 1.2ms preprocess, 646.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 664.9ms\n",
      "Speed: 1.4ms preprocess, 664.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 648.2ms\n",
      "Speed: 1.2ms preprocess, 648.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 687.4ms\n",
      "Speed: 1.1ms preprocess, 687.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 664.3ms\n",
      "Speed: 1.9ms preprocess, 664.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 652.3ms\n",
      "Speed: 1.8ms preprocess, 652.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 669.0ms\n",
      "Speed: 1.8ms preprocess, 669.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 664.6ms\n",
      "Speed: 1.6ms preprocess, 664.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 truck, 1 traffic light, 684.9ms\n",
      "Speed: 1.2ms preprocess, 684.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 truck, 1 traffic light, 683.0ms\n",
      "Speed: 1.2ms preprocess, 683.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 674.7ms\n",
      "Speed: 1.4ms preprocess, 674.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 690.5ms\n",
      "Speed: 1.9ms preprocess, 690.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 684.0ms\n",
      "Speed: 1.4ms preprocess, 684.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 694.2ms\n",
      "Speed: 1.3ms preprocess, 694.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 694.2ms\n",
      "Speed: 1.6ms preprocess, 694.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 656.0ms\n",
      "Speed: 1.3ms preprocess, 656.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 686.5ms\n",
      "Speed: 1.5ms preprocess, 686.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 657.4ms\n",
      "Speed: 1.7ms preprocess, 657.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 672.9ms\n",
      "Speed: 1.5ms preprocess, 672.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 648.1ms\n",
      "Speed: 1.2ms preprocess, 648.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 665.3ms\n",
      "Speed: 1.3ms preprocess, 665.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 657.9ms\n",
      "Speed: 1.2ms preprocess, 657.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 650.8ms\n",
      "Speed: 1.7ms preprocess, 650.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 667.2ms\n",
      "Speed: 1.7ms preprocess, 667.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 659.1ms\n",
      "Speed: 1.2ms preprocess, 659.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 652.5ms\n",
      "Speed: 1.2ms preprocess, 652.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 647.2ms\n",
      "Speed: 1.9ms preprocess, 647.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 674.5ms\n",
      "Speed: 1.6ms preprocess, 674.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 674.4ms\n",
      "Speed: 1.2ms preprocess, 674.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 646.1ms\n",
      "Speed: 1.2ms preprocess, 646.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 643.0ms\n",
      "Speed: 2.0ms preprocess, 643.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 658.2ms\n",
      "Speed: 1.3ms preprocess, 658.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 truck, 1 traffic light, 647.2ms\n",
      "Speed: 1.3ms preprocess, 647.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 truck, 670.5ms\n",
      "Speed: 1.9ms preprocess, 670.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 truck, 674.1ms\n",
      "Speed: 1.2ms preprocess, 674.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 truck, 656.3ms\n",
      "Speed: 1.3ms preprocess, 656.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 5 cars, 651.3ms\n",
      "Speed: 1.2ms preprocess, 651.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 persons, 4 cars, 1 truck, 657.5ms\n",
      "Speed: 1.9ms preprocess, 657.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 persons, 4 cars, 1 truck, 670.5ms\n",
      "Speed: 1.9ms preprocess, 670.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 persons, 4 cars, 1 truck, 647.8ms\n",
      "Speed: 1.2ms preprocess, 647.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 5 persons, 4 cars, 1 truck, 638.0ms\n",
      "Speed: 1.2ms preprocess, 638.0ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 truck, 642.2ms\n",
      "Speed: 1.2ms preprocess, 642.2ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 truck, 1 traffic light, 649.0ms\n",
      "Speed: 1.2ms preprocess, 649.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 truck, 1 traffic light, 666.0ms\n",
      "Speed: 1.6ms preprocess, 666.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 2 trucks, 1 traffic light, 648.8ms\n",
      "Speed: 1.3ms preprocess, 648.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 2 trucks, 1 traffic light, 671.0ms\n",
      "Speed: 1.3ms preprocess, 671.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 2 trucks, 1 traffic light, 673.9ms\n",
      "Speed: 1.5ms preprocess, 673.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 2 trucks, 1 traffic light, 665.3ms\n",
      "Speed: 1.6ms preprocess, 665.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 2 trucks, 1 traffic light, 683.1ms\n",
      "Speed: 2.1ms preprocess, 683.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 633.1ms\n",
      "Speed: 1.2ms preprocess, 633.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 653.8ms\n",
      "Speed: 1.2ms preprocess, 653.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 663.1ms\n",
      "Speed: 1.4ms preprocess, 663.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 659.6ms\n",
      "Speed: 1.2ms preprocess, 659.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 648.4ms\n",
      "Speed: 1.2ms preprocess, 648.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 667.2ms\n",
      "Speed: 1.4ms preprocess, 667.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 668.3ms\n",
      "Speed: 1.3ms preprocess, 668.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 654.5ms\n",
      "Speed: 1.7ms preprocess, 654.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 640.9ms\n",
      "Speed: 1.2ms preprocess, 640.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 640.3ms\n",
      "Speed: 1.3ms preprocess, 640.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 654.7ms\n",
      "Speed: 1.2ms preprocess, 654.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 644.5ms\n",
      "Speed: 1.2ms preprocess, 644.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 676.8ms\n",
      "Speed: 1.2ms preprocess, 676.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 676.2ms\n",
      "Speed: 1.5ms preprocess, 676.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 660.6ms\n",
      "Speed: 1.2ms preprocess, 660.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 678.1ms\n",
      "Speed: 1.2ms preprocess, 678.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 638.5ms\n",
      "Speed: 1.2ms preprocess, 638.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 631.8ms\n",
      "Speed: 1.8ms preprocess, 631.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 650.1ms\n",
      "Speed: 1.2ms preprocess, 650.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 666.8ms\n",
      "Speed: 2.0ms preprocess, 666.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 696.5ms\n",
      "Speed: 1.2ms preprocess, 696.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 659.3ms\n",
      "Speed: 2.0ms preprocess, 659.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 667.4ms\n",
      "Speed: 1.7ms preprocess, 667.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 650.7ms\n",
      "Speed: 1.2ms preprocess, 650.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 676.3ms\n",
      "Speed: 1.5ms preprocess, 676.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 665.7ms\n",
      "Speed: 1.2ms preprocess, 665.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 655.0ms\n",
      "Speed: 1.2ms preprocess, 655.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 654.9ms\n",
      "Speed: 1.3ms preprocess, 654.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 1 traffic light, 659.5ms\n",
      "Speed: 1.4ms preprocess, 659.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 1 traffic light, 650.9ms\n",
      "Speed: 1.4ms preprocess, 650.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 1 traffic light, 665.5ms\n",
      "Speed: 1.2ms preprocess, 665.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 2 trucks, 1 traffic light, 666.6ms\n",
      "Speed: 1.2ms preprocess, 666.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 5 cars, 1 traffic light, 679.1ms\n",
      "Speed: 1.2ms preprocess, 679.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 1 traffic light, 652.8ms\n",
      "Speed: 1.2ms preprocess, 652.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 1 traffic light, 672.3ms\n",
      "Speed: 2.3ms preprocess, 672.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 1 traffic light, 669.2ms\n",
      "Speed: 2.0ms preprocess, 669.2ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 1 traffic light, 665.1ms\n",
      "Speed: 1.6ms preprocess, 665.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 1 truck, 1 traffic light, 684.5ms\n",
      "Speed: 1.2ms preprocess, 684.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 677.5ms\n",
      "Speed: 1.2ms preprocess, 677.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 668.6ms\n",
      "Speed: 1.8ms preprocess, 668.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 694.4ms\n",
      "Speed: 1.2ms preprocess, 694.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 674.1ms\n",
      "Speed: 1.2ms preprocess, 674.1ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 653.9ms\n",
      "Speed: 1.6ms preprocess, 653.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 663.4ms\n",
      "Speed: 1.2ms preprocess, 663.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 2 trucks, 1 traffic light, 666.4ms\n",
      "Speed: 1.1ms preprocess, 666.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 642.8ms\n",
      "Speed: 1.7ms preprocess, 642.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 663.3ms\n",
      "Speed: 1.2ms preprocess, 663.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 660.3ms\n",
      "Speed: 1.2ms preprocess, 660.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 695.3ms\n",
      "Speed: 1.3ms preprocess, 695.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 666.5ms\n",
      "Speed: 2.0ms preprocess, 666.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 truck, 673.6ms\n",
      "Speed: 1.2ms preprocess, 673.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 1 car, 3 trucks, 667.9ms\n",
      "Speed: 1.8ms preprocess, 667.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 652.3ms\n",
      "Speed: 1.6ms preprocess, 652.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 657.6ms\n",
      "Speed: 1.5ms preprocess, 657.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 671.6ms\n",
      "Speed: 1.3ms preprocess, 671.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 690.5ms\n",
      "Speed: 1.5ms preprocess, 690.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 664.8ms\n",
      "Speed: 2.0ms preprocess, 664.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 667.8ms\n",
      "Speed: 1.2ms preprocess, 667.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 691.2ms\n",
      "Speed: 2.2ms preprocess, 691.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 668.6ms\n",
      "Speed: 1.2ms preprocess, 668.6ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 671.0ms\n",
      "Speed: 1.2ms preprocess, 671.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 690.3ms\n",
      "Speed: 1.2ms preprocess, 690.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 696.1ms\n",
      "Speed: 1.3ms preprocess, 696.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 645.4ms\n",
      "Speed: 1.5ms preprocess, 645.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 652.5ms\n",
      "Speed: 1.3ms preprocess, 652.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 648.8ms\n",
      "Speed: 1.3ms preprocess, 648.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 657.3ms\n",
      "Speed: 1.8ms preprocess, 657.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 674.8ms\n",
      "Speed: 1.5ms preprocess, 674.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 660.8ms\n",
      "Speed: 1.9ms preprocess, 660.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 666.3ms\n",
      "Speed: 1.2ms preprocess, 666.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 2 cars, 2 trucks, 1 traffic light, 665.4ms\n",
      "Speed: 1.2ms preprocess, 665.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 truck, 1 traffic light, 685.5ms\n",
      "Speed: 1.3ms preprocess, 685.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 693.2ms\n",
      "Speed: 1.4ms preprocess, 693.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 669.4ms\n",
      "Speed: 1.6ms preprocess, 669.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 675.5ms\n",
      "Speed: 1.3ms preprocess, 675.5ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 2 cars, 2 trucks, 1 traffic light, 678.8ms\n",
      "Speed: 1.2ms preprocess, 678.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 truck, 1 traffic light, 681.9ms\n",
      "Speed: 1.4ms preprocess, 681.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 628.0ms\n",
      "Speed: 1.7ms preprocess, 628.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 645.3ms\n",
      "Speed: 1.2ms preprocess, 645.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 667.5ms\n",
      "Speed: 1.2ms preprocess, 667.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 678.4ms\n",
      "Speed: 1.3ms preprocess, 678.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 673.3ms\n",
      "Speed: 1.1ms preprocess, 673.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 679.6ms\n",
      "Speed: 2.2ms preprocess, 679.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 3 cars, 1 truck, 1 traffic light, 665.6ms\n",
      "Speed: 2.0ms preprocess, 665.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 669.6ms\n",
      "Speed: 1.3ms preprocess, 669.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 4 persons, 4 cars, 1 traffic light, 669.0ms\n",
      "Speed: 1.3ms preprocess, 669.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 669.3ms\n",
      "Speed: 1.4ms preprocess, 669.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 664.9ms\n",
      "Speed: 2.1ms preprocess, 664.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 677.1ms\n",
      "Speed: 1.5ms preprocess, 677.1ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 669.1ms\n",
      "Speed: 1.2ms preprocess, 669.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 679.6ms\n",
      "Speed: 1.3ms preprocess, 679.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 684.4ms\n",
      "Speed: 1.2ms preprocess, 684.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 664.0ms\n",
      "Speed: 1.4ms preprocess, 664.0ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 663.6ms\n",
      "Speed: 2.1ms preprocess, 663.6ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 685.4ms\n",
      "Speed: 1.2ms preprocess, 685.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 640.9ms\n",
      "Speed: 1.2ms preprocess, 640.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 680.0ms\n",
      "Speed: 1.2ms preprocess, 680.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 675.9ms\n",
      "Speed: 1.9ms preprocess, 675.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 4 cars, 2 traffic lights, 661.7ms\n",
      "Speed: 1.2ms preprocess, 661.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 3 cars, 1 truck, 1 traffic light, 664.3ms\n",
      "Speed: 2.0ms preprocess, 664.3ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 656.7ms\n",
      "Speed: 1.2ms preprocess, 656.7ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 652.4ms\n",
      "Speed: 1.3ms preprocess, 652.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 traffic light, 654.5ms\n",
      "Speed: 1.5ms preprocess, 654.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 1 truck, 1 traffic light, 644.5ms\n",
      "Speed: 1.2ms preprocess, 644.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 654.0ms\n",
      "Speed: 2.0ms preprocess, 654.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 660.9ms\n",
      "Speed: 1.1ms preprocess, 660.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 2 trucks, 1 traffic light, 665.9ms\n",
      "Speed: 1.2ms preprocess, 665.9ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 667.9ms\n",
      "Speed: 1.4ms preprocess, 667.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 3 cars, 2 trucks, 1 traffic light, 669.8ms\n",
      "Speed: 1.4ms preprocess, 669.8ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 666.4ms\n",
      "Speed: 1.4ms preprocess, 666.4ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 668.9ms\n",
      "Speed: 1.2ms preprocess, 668.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 3 persons, 4 cars, 1 truck, 1 traffic light, 669.9ms\n",
      "Speed: 1.7ms preprocess, 669.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Perform tracking for the first counter, options: tracker=\"bytetrack.yaml\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m tracks \u001b[38;5;241m=\u001b[39m \u001b[43mtracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses_to_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m im0 \u001b[38;5;241m=\u001b[39m counter_1\u001b[38;5;241m.\u001b[39mstart_counting(im0, tracks)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Perform tracking for the second counter\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ultralytics/engine/model.py:493\u001b[0m, in \u001b[0;36mModel.track\u001b[0;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# batch-size 1 for tracking in videos\u001b[39;00m\n\u001b[1;32m    492\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ultralytics/engine/model.py:453\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ultralytics/engine/predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ultralytics/engine/predictor.py:248\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 248\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ultralytics/engine/predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    141\u001b[0m )\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ultralytics/nn/autobackend.py:453\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[0;32m--> 453\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ultralytics/nn/tasks.py:89\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ultralytics/nn/tasks.py:107\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ultralytics/nn/tasks.py:128\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 128\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    129\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ultralytics/nn/modules/head.py:47\u001b[0m, in \u001b[0;36mDetect.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Concatenates and returns predicted bounding boxes and class probabilities.\"\"\"\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnl):\n\u001b[0;32m---> 47\u001b[0m     x[i] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2[i](x[i]), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv3\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:  \u001b[38;5;66;03m# Training path\u001b[39;00m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/ultralytics/nn/modules/conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO, solutions\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(\"yolov9e.pt\")\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"resources/DJI_0505.MP4\")\n",
    "assert cap.isOpened(), \"Error reading video file\" \n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "classes_to_count = list(range(0, 23))  # classes to count \n",
    "\n",
    "# Define the lines or regions points\n",
    "line_points_1 = [(300, 600), (700, 550)]  # first line points\n",
    "line_points_2 = [(800, 550), (1700, 350)]  # second line points\n",
    "line_points_3 = [(174, 1150), (174, 1800)]  # second line points\n",
    "line_points_4 = [(640, 1674), (1006, 1578)]  # second line points\n",
    "\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"out_object_counting_output.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init Object Counters\n",
    "counter_1 = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=line_points_1,\n",
    "    classes_names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=2,\n",
    "    text_offset=(0, 0),\n",
    "    count_reg_color=(229, 255, 204),  # Very light green\n",
    "    count_bg_color=(229, 255, 204)  # Very light green\n",
    ")\n",
    "\n",
    "counter_2 = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=line_points_2,\n",
    "    classes_names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=2,\n",
    "    text_offset=(-250, 0),\n",
    "    count_reg_color=(153, 204, 255),  # Light blue\n",
    "    count_bg_color=(153, 204, 255)  # Light blue\n",
    ")\n",
    "\n",
    "counter_3 = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=line_points_3,\n",
    "    classes_names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=2,\n",
    "    text_offset=(-500, 0),\n",
    "    count_reg_color=(255, 204, 204),  # Light red\n",
    "    count_bg_color=(255, 204, 204)  # Light red\n",
    ")\n",
    "\n",
    "counter_4 = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=line_points_4,\n",
    "    classes_names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=2,\n",
    "    text_offset=(-750, 0),\n",
    "    count_reg_color=(210, 180, 140),  # Light brown\n",
    "    count_bg_color=(210, 180, 140)  # Light brown\n",
    ")\n",
    "\n",
    "\n",
    "# Init separate trackers for each counter\n",
    "tracker = model  # Tracker for the first counter\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    # Perform tracking for the first counter, options: tracker=\"bytetrack.yaml\"\n",
    "    tracks = tracker.track(im0, persist=True, show=False, classes=classes_to_count)\n",
    "    \n",
    "    im0 = counter_1.start_counting(im0, tracks)\n",
    "\n",
    "    # Perform tracking for the second counter\n",
    "    im0 = counter_2.start_counting(im0, tracks)\n",
    "    \n",
    "    im0 = counter_3.start_counting(im0, tracks)\n",
    "    \n",
    "    im0 = counter_4.start_counting(im0, tracks)\n",
    "    \n",
    "    # Write the frame to the output video\n",
    "    video_writer.write(im0)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Speed and Prevent the detection of stationary objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line Counter Initiated.\n",
      "Line Counter Initiated.\n",
      "Line Counter Initiated.\n",
      "Line Counter Initiated.\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 878.0ms\n",
      "Speed: 2.3ms preprocess, 878.0ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 5 cars, 2 trucks, 805.0ms\n",
      "Speed: 1.5ms preprocess, 805.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 812.5ms\n",
      "Speed: 1.5ms preprocess, 812.5ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 760.9ms\n",
      "Speed: 1.5ms preprocess, 760.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 753.8ms\n",
      "Speed: 1.6ms preprocess, 753.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 6 cars, 1 truck, 764.6ms\n",
      "Speed: 1.2ms preprocess, 764.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 7 cars, 1 truck, 833.3ms\n",
      "Speed: 1.8ms preprocess, 833.3ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 1 person, 8 cars, 1 truck, 855.2ms\n",
      "Speed: 1.4ms preprocess, 855.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 88\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     86\u001b[0m frame_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Increment frame counter\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m tracks \u001b[38;5;241m=\u001b[39m \u001b[43mtracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses_to_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvid_stride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m tracks:\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m track \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mboxes:\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/engine/model.py:493\u001b[0m, in \u001b[0;36mModel.track\u001b[0;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# batch-size 1 for tracking in videos\u001b[39;00m\n\u001b[1;32m    492\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/engine/model.py:453\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/engine/predictor.py:168\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/engine/predictor.py:248\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 248\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/engine/predictor.py:142\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    137\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    138\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    141\u001b[0m )\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/nn/autobackend.py:453\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[0;32m--> 453\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/nn/tasks.py:89\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/nn/tasks.py:107\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/nn/tasks.py:128\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 128\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    129\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/nn/modules/block.py:596\u001b[0m, in \u001b[0;36mRepNCSPELAN4.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through RepNCSPELAN4 layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    595\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 596\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv3\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv4(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/nn/modules/block.py:596\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through RepNCSPELAN4 layer.\"\"\"\u001b[39;00m\n\u001b[1;32m    595\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 596\u001b[0m y\u001b[38;5;241m.\u001b[39mextend((\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv3])\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv4(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/nn/modules/block.py:254\u001b[0m, in \u001b[0;36mC3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    253\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through the CSP bottleneck with 2 convolutions.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/multi_vehicle_count/ultralytics/nn/modules/conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/modules/activation.py:396\u001b[0m, in \u001b[0;36mSiLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:2101\u001b[0m, in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2099\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(silu, (\u001b[38;5;28minput\u001b[39m,), \u001b[38;5;28minput\u001b[39m, inplace\u001b[38;5;241m=\u001b[39minplace)\n\u001b[1;32m   2100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m-> 2101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39msilu(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO, solutions\n",
    "import time\n",
    "\n",
    "model = YOLO(\"yolov9e.pt\")\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(\"resources/DJI_0505.MP4\")\n",
    "assert cap.isOpened(), \"Error reading video file\" \n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "classes_to_count = list(range(0, 23))  # classes to count \n",
    "\n",
    "# Define the lines or regions points\n",
    "line_points_1 = [(300, 600), (700, 550)]  \n",
    "line_points_2 = [(800, 550), (1700, 350)] \n",
    "line_points_3 = [(174, 1150), (174, 1800)]\n",
    "line_points_4 = [(640, 1674), (1006, 1578)] \n",
    "\n",
    "\n",
    "# Video writer\n",
    "video_writer = cv2.VideoWriter(\"stationary_object_counting_output.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "# Init Object Counters\n",
    "counter_1 = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=line_points_1,\n",
    "    classes_names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=2,\n",
    "    text_offset=(0, 0),\n",
    "    count_reg_color=(229, 255, 204), \n",
    "    count_bg_color=(229, 255, 204)  \n",
    ")\n",
    "\n",
    "counter_2 = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=line_points_2,\n",
    "    classes_names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=2,\n",
    "    text_offset=(-250, 0),\n",
    "    count_reg_color=(153, 204, 255),  \n",
    "    count_bg_color=(153, 204, 255)  \n",
    ")\n",
    "\n",
    "counter_3 = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=line_points_3,\n",
    "    classes_names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=2,\n",
    "    text_offset=(-500, 0),\n",
    "    count_reg_color=(255, 204, 204),  \n",
    "    count_bg_color=(255, 204, 204)  \n",
    ")\n",
    "\n",
    "counter_4 = solutions.ObjectCounter(\n",
    "    view_img=True,\n",
    "    reg_pts=line_points_4,\n",
    "    classes_names=model.names,\n",
    "    draw_tracks=True,\n",
    "    line_thickness=2,\n",
    "    text_offset=(-750, 0),\n",
    "    count_reg_color=(210, 180, 140),  \n",
    "    count_bg_color=(210, 180, 140)  \n",
    ")\n",
    "\n",
    "# Initialize tracking dictionary\n",
    "last_positions = {}\n",
    "stationary_ids = set()\n",
    "frame_interval = 30  # Check position every x frames\n",
    "frame_count = 0  # Initialize frame counter\n",
    "\n",
    "movement_threshold = 2  # Minimum pixels an object must move to be considered in motion\n",
    "pixel_to_meter = 0.5  # Conversion factor: 1 pixel = 0.5 meters\n",
    "\n",
    "tracker = model  \n",
    "\n",
    "while cap.isOpened():\n",
    "    success, im0 = cap.read()\n",
    "    if not success:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    frame_count += 1  # Increment frame counter\n",
    "\n",
    "    tracks = tracker.track(im0, persist=True, show=False, classes=classes_to_count, vid_stride=5)\n",
    "        \n",
    "    for result in tracks:\n",
    "        for track in result.boxes:\n",
    "            id = int(track.id)\n",
    "\n",
    "            if track.xyxy.numel() == 4:\n",
    "                x_min, y_min, x_max, y_max = track.xyxy[0]  # Unpack from the first row\n",
    "\n",
    "                # Calculate center coordinates (x, y), width (w), and height (h)\n",
    "                x = (x_min + x_max) / 2\n",
    "                y = (y_min + y_max) / 2\n",
    "                w = x_max - x_min\n",
    "                h = y_max - y_min\n",
    "\n",
    "            current_time = time.time()  # Get the current timestamp\n",
    "            \n",
    "            if frame_count % frame_interval == 0:\n",
    "                if id in last_positions:\n",
    "                    last_x, last_y, _, _, last_time = last_positions[id]\n",
    "                    # Calculate movement\n",
    "                    distance_pixels = ((last_x - x) ** 2 + (last_y - y) ** 2) ** pixel_to_meter\n",
    "                    delta_time = current_time - last_time\n",
    "\n",
    "                    if distance_pixels < movement_threshold:\n",
    "                        stationary_ids.add(id)\n",
    "                    else:\n",
    "                        stationary_ids.discard(id)\n",
    "                    \n",
    "                    # print(f\"Object {stationary_ids} is stationary.\")  \n",
    "                    \n",
    "                    speed_pixels_per_second = distance_pixels / delta_time\n",
    "                    # Convert speed to kilometers per hour\n",
    "                    speed_km_per_hour = speed_pixels_per_second * 3.6\n",
    "\n",
    "                    print(f\"Object {id} moved with speed {speed_km_per_hour:.2f} km/h\")\n",
    "\n",
    "                    \n",
    "            # Update position and timestamp x frames\n",
    "            last_positions[id] = (x, y, w, h, current_time)\n",
    "\n",
    "\n",
    "    # Perform counting and draw tracks for each counter\n",
    "    im0 = counter_1.start_counting(im0, tracks, stationary_ids)\n",
    "    im0 = counter_2.start_counting(im0, tracks, stationary_ids)\n",
    "    im0 = counter_3.start_counting(im0, tracks, stationary_ids)\n",
    "    im0 = counter_4.start_counting(im0, tracks, stationary_ids)\n",
    "    \n",
    "    # Write the frame to the output video\n",
    "    video_writer.write(im0)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
